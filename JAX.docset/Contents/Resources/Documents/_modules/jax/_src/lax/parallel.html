
<!DOCTYPE html>


<html lang="en" data-content_root="../../../../" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <title>jax._src.lax.parallel &#8212; JAX  documentation</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="../../../../_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="../../../../_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="../../../../_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="../../../../_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="../../../../_static/pygments.css?v=a746c00c" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/styles/sphinx-book-theme.css?v=384b581d" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/plot_directive.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css?v=0a3b3ea7" />
    <link rel="stylesheet" type="text/css" href="../../../../_static/style.css?v=02ed413a" />
    <link rel="stylesheet" href="../../../../_static/style.css" type="text/css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="../../../../_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script src="../../../../_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="../../../../_static/doctools.js?v=9a2dae69"></script>
    <script src="../../../../_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="../../../../_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="../../../../_static/copybutton.js?v=f281be69"></script>
    <script src="../../../../_static/scripts/sphinx-book-theme.js?v=efea14e4"></script>
    <script src="../../../../_static/design-tabs.js?v=36754332"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = '_modules/jax/_src/lax/parallel';</script>
    <link rel="icon" href="../../../../_static/favicon.png"/>
    <link rel="index" title="Index" href="../../../../genindex.html" />
    <link rel="search" title="Search" href="../../../../search.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="../../../../search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search..."
         aria-label="Search..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
        
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="../../../../index.html">
  
  
  
  
  
    
    
      
    
    
    <img src="../../../../_static/jax_logo_250px.png" class="logo__image only-light" alt="JAX  documentation - Home"/>
    <script>document.write(`<img src="../../../../_static/jax_logo_250px.png" class="logo__image only-dark" alt="JAX  documentation - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Getting Started</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../installation.html">Installing JAX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/quickstart.html">JAX Quickstart</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/thinking_in_jax.html">How to Think in JAX</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../notebooks/Common_Gotchas_in_JAX.html">ðŸ”ª JAX - The Sharp Bits ðŸ”ª</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../faq.html">JAX Frequently Asked Questions (FAQ)</a></li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../jax-101/index.html">Tutorial: JAX 101</a><input class="toctree-checkbox" id="toctree-checkbox-1" name="toctree-checkbox-1" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-1"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/01-jax-basics.html">JAX As Accelerated NumPy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/02-jitting.html">Just In Time Compilation with JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/03-vectorization.html">Automatic Vectorization in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/04-advanced-autodiff.html">Advanced Automatic Differentiation in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/05-random-numbers.html">Pseudo Random Numbers in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/05.1-pytrees.html">Working with Pytrees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/06-parallelism.html">Parallel Evaluation in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax-101/07-state.html">Stateful Computations in JAX</a></li>
</ul>
</li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Further Resources</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../user_guides.html">User Guides</a><input class="toctree-checkbox" id="toctree-checkbox-2" name="toctree-checkbox-2" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-2"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../profiling.html">Profiling JAX programs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../device_memory_profiling.html">Device Memory Profiling</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../debugging/index.html">Runtime value debugging in JAX</a><input class="toctree-checkbox" id="toctree-checkbox-3" name="toctree-checkbox-3" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-3"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../debugging/print_breakpoint.html"><code class="docutils literal notranslate"><span class="pre">jax.debug.print</span></code> and <code class="docutils literal notranslate"><span class="pre">jax.debug.breakpoint</span></code></a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../debugging/checkify_guide.html">The <code class="docutils literal notranslate"><span class="pre">checkify</span></code> transformation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../debugging/flags.html">JAX debugging flags</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../gpu_performance_tips.html">GPU performance tips</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../persistent_compilation_cache.html">Persistent Compilation Cache</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jaxpr.html">Understanding Jaxprs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/external_callbacks.html">External Callbacks in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../type_promotion.html">Type promotion semantics</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../pytrees.html">Pytrees</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../aot.html">Ahead-of-time lowering and compilation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../errors.html">JAX Errors</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../transfer_guard.html">Transfer guard</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../pallas/index.html">Pallas: a JAX kernel language</a><input class="toctree-checkbox" id="toctree-checkbox-4" name="toctree-checkbox-4" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-4"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../pallas/design.html">Pallas Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../pallas/quickstart.html">Pallas Quickstart</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../pallas/tpu/index.html">Pallas TPU</a><input class="toctree-checkbox" id="toctree-checkbox-5" name="toctree-checkbox-5" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-5"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../pallas/tpu/details.html">Writing TPU kernels with Pallas</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../pallas/tpu/pipelining.html">Pipelining and <code class="docutils literal notranslate"><span class="pre">BlockSpec</span></code>s</a></li>
</ul>
</li>
</ul>
</li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../advanced_guide.html">Advanced Tutorials</a><input class="toctree-checkbox" id="toctree-checkbox-6" name="toctree-checkbox-6" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-6"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/neural_network_with_tfds_data.html">Training a Simple Neural Network, with tensorflow/datasets Data Loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/Neural_Network_and_Data_Loading.html">Training a Simple Neural Network, with PyTorch Data Loading</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/vmapped_log_probs.html">Autobatching for Bayesian Inference</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../multi_process.html">Using JAX in multi-host and multi-process environments</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/Distributed_arrays_and_automatic_parallelization.html">Distributed arrays and automatic parallelization</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/shard_map.html">SPMD multi-device parallelism with <code class="docutils literal notranslate"><span class="pre">shard_map</span></code></a></li>



<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/xmap_tutorial.html">Named axes and easy-to-revise parallelism with <code class="docutils literal notranslate"><span class="pre">xmap</span></code></a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/autodiff_cookbook.html">The Autodiff Cookbook</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/Custom_derivative_rules_for_Python_code.html">Custom derivative rules for JAX-transformable Python functions</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/autodiff_remat.html">Control autodiffâ€™s saved values with <code class="docutils literal notranslate"><span class="pre">jax.checkpoint</span></code> (aka <code class="docutils literal notranslate"><span class="pre">jax.remat</span></code>)</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/How_JAX_primitives_work.html">How JAX primitives work</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/Writing_custom_interpreters_in_Jax.html">Writing custom Jaxpr interpreters in JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../Custom_Operation_for_GPUs.html">Custom operations for GPUs with C++ and CUDA</a></li>

<li class="toctree-l2"><a class="reference internal" href="../../../../notebooks/convolutions.html">Generalized Convolutions in JAX</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../contributor_guide.html">Developer Documentation</a><input class="toctree-checkbox" id="toctree-checkbox-7" name="toctree-checkbox-7" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-7"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../contributing.html">Contributing to JAX</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../developer.html">Building from source</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax_internal_api.html">Internal APIs</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../autodidax.html">Autodidax: JAX core from scratch</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jep/index.html">JAX Enhancement Proposals (JEPs)</a><input class="toctree-checkbox" id="toctree-checkbox-8" name="toctree-checkbox-8" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-8"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/263-prng.html">263: JAX PRNG Design</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/2026-custom-derivatives.html">2026: Custom JVP/VJP rules for JAX-transformable functions</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/4008-custom-vjp-update.html">4008: Custom VJP and `nondiff_argnums` update</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/4410-omnistaging.html">4410: Omnistaging</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/9263-typed-keys.html">9263: Typed keys &amp; pluggable RNGs</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/9407-type-promotion.html">9407: Design of Type Promotion Semantics for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/9419-jax-versioning.html">9419: Jax and Jaxlib versioning</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/10657-sequencing-effects.html">10657: Sequencing side-effects in JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/11830-new-remat-checkpoint.html">11830: `jax.remat` / `jax.checkpoint` new implementation</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/12049-type-annotations.html">12049: Type Annotation Roadmap for JAX</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/14273-shard-map.html">14273: `shard_map` (`shmap`) for simple per-device code</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/15856-jex.html">15856: `jax.extend`, an extensions module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/17111-shmap-transpose.html">17111: Efficient transposition of `shard_map` (and other maps)</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jep/18137-numpy-scipy-scope.html">18137: Scope of JAX NumPy &amp; SciPy Wrappers</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../investigating_a_regression.html">Investigating a regression</a></li>
</ul>
</li>
<li class="toctree-l1"><a class="reference internal" href="../../../../building_on_jax.html">Building on JAX</a></li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../notes.html">Notes</a><input class="toctree-checkbox" id="toctree-checkbox-9" name="toctree-checkbox-9" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-9"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2"><a class="reference internal" href="../../../../api_compatibility.html">API compatibility</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../deprecation.html">Python and NumPy version support policy</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax_array_migration.html">jax.Array migration</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../async_dispatch.html">Asynchronous dispatch</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../concurrency.html">Concurrency</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../gpu_memory_allocation.html">GPU memory allocation</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../rank_promotion_warning.html">Rank promotion warning</a></li>
</ul>
</li>
<li class="toctree-l1 has-children"><a class="reference internal" href="../../../../jax.html">Public API: jax package</a><input class="toctree-checkbox" id="toctree-checkbox-10" name="toctree-checkbox-10" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-10"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.numpy.html"><code class="docutils literal notranslate"><span class="pre">jax.numpy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-11" name="toctree-checkbox-11" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-11"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.fft.html">jax.numpy.fft.fft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.fft2.html">jax.numpy.fft.fft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.fftfreq.html">jax.numpy.fft.fftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.fftn.html">jax.numpy.fft.fftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.fftshift.html">jax.numpy.fft.fftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.hfft.html">jax.numpy.fft.hfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.ifft.html">jax.numpy.fft.ifft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.ifft2.html">jax.numpy.fft.ifft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.ifftn.html">jax.numpy.fft.ifftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.ifftshift.html">jax.numpy.fft.ifftshift</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.ihfft.html">jax.numpy.fft.ihfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.irfft.html">jax.numpy.fft.irfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.irfft2.html">jax.numpy.fft.irfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.irfftn.html">jax.numpy.fft.irfftn</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.rfft.html">jax.numpy.fft.rfft</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.rfft2.html">jax.numpy.fft.rfft2</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.rfftfreq.html">jax.numpy.fft.rfftfreq</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.numpy.fft.rfftn.html">jax.numpy.fft.rfftn</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.scipy.html"><code class="docutils literal notranslate"><span class="pre">jax.scipy</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-12" name="toctree-checkbox-12" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-12"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.scipy.stats.bernoulli.logpmf.html">jax.scipy.stats.bernoulli.logpmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.scipy.stats.bernoulli.pmf.html">jax.scipy.stats.bernoulli.pmf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.scipy.stats.bernoulli.cdf.html">jax.scipy.stats.bernoulli.cdf</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../_autosummary/jax.scipy.stats.bernoulli.ppf.html">jax.scipy.stats.bernoulli.ppf</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.lax.html"><code class="docutils literal notranslate"><span class="pre">jax.lax</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.random.html"><code class="docutils literal notranslate"><span class="pre">jax.random</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.sharding.html"><code class="docutils literal notranslate"><span class="pre">jax.sharding</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.debug.html"><code class="docutils literal notranslate"><span class="pre">jax.debug</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.dlpack.html"><code class="docutils literal notranslate"><span class="pre">jax.dlpack</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.distributed.html"><code class="docutils literal notranslate"><span class="pre">jax.distributed</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.dtypes.html"><code class="docutils literal notranslate"><span class="pre">jax.dtypes</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.flatten_util.html"><code class="docutils literal notranslate"><span class="pre">jax.flatten_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.image.html"><code class="docutils literal notranslate"><span class="pre">jax.image</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.nn.html"><code class="docutils literal notranslate"><span class="pre">jax.nn</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-13" name="toctree-checkbox-13" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-13"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.nn.initializers.html"><code class="docutils literal notranslate"><span class="pre">jax.nn.initializers</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.ops.html"><code class="docutils literal notranslate"><span class="pre">jax.ops</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.profiler.html"><code class="docutils literal notranslate"><span class="pre">jax.profiler</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.stages.html"><code class="docutils literal notranslate"><span class="pre">jax.stages</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.tree.html"><code class="docutils literal notranslate"><span class="pre">jax.tree</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.tree_util.html"><code class="docutils literal notranslate"><span class="pre">jax.tree_util</span></code> module</a></li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.typing.html"><code class="docutils literal notranslate"><span class="pre">jax.typing</span></code> module</a></li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.extend.html"><code class="docutils literal notranslate"><span class="pre">jax.extend</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-14" name="toctree-checkbox-14" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-14"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.extend.linear_util.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.linear_util</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.extend.mlir.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.mlir</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.extend.random.html"><code class="docutils literal notranslate"><span class="pre">jax.extend.random</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.example_libraries.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-15" name="toctree-checkbox-15" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-15"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.example_libraries.optimizers.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.optimizers</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.example_libraries.stax.html"><code class="docutils literal notranslate"><span class="pre">jax.example_libraries.stax</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2 has-children"><a class="reference internal" href="../../../../jax.experimental.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-16" name="toctree-checkbox-16" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-16"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.array_api.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.array_api</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.checkify.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.checkify</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.host_callback.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.host_callback</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.maps.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.maps</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.pjit.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.pjit</span></code> module</a></li>
<li class="toctree-l3 has-children"><a class="reference internal" href="../../../../jax.experimental.sparse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.sparse</span></code> module</a><input class="toctree-checkbox" id="toctree-checkbox-17" name="toctree-checkbox-17" type="checkbox"/><label class="toctree-toggle" for="toctree-checkbox-17"><i class="fa-solid fa-chevron-down"></i></label><ul>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.BCOO.html">jax.experimental.sparse.BCOO</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_broadcast_in_dim.html">jax.experimental.sparse.bcoo_broadcast_in_dim</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_concatenate.html">jax.experimental.sparse.bcoo_concatenate</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_dot_general.html">jax.experimental.sparse.bcoo_dot_general</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_dot_general_sampled.html">jax.experimental.sparse.bcoo_dot_general_sampled</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_dynamic_slice.html">jax.experimental.sparse.bcoo_dynamic_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_extract.html">jax.experimental.sparse.bcoo_extract</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_fromdense.html">jax.experimental.sparse.bcoo_fromdense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_gather.html">jax.experimental.sparse.bcoo_gather</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_multiply_dense.html">jax.experimental.sparse.bcoo_multiply_dense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_multiply_sparse.html">jax.experimental.sparse.bcoo_multiply_sparse</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_update_layout.html">jax.experimental.sparse.bcoo_update_layout</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_reduce_sum.html">jax.experimental.sparse.bcoo_reduce_sum</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_reshape.html">jax.experimental.sparse.bcoo_reshape</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_slice.html">jax.experimental.sparse.bcoo_slice</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_sort_indices.html">jax.experimental.sparse.bcoo_sort_indices</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_squeeze.html">jax.experimental.sparse.bcoo_squeeze</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_sum_duplicates.html">jax.experimental.sparse.bcoo_sum_duplicates</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_todense.html">jax.experimental.sparse.bcoo_todense</a></li>
<li class="toctree-l4"><a class="reference internal" href="../../../../_autosummary/jax.experimental.sparse.bcoo_transpose.html">jax.experimental.sparse.bcoo_transpose</a></li>
</ul>
</li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.jet.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.jet</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.custom_partitioning.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.custom_partitioning</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.multihost_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.multihost_utils</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.compilation_cache.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.compilation_cache</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.key_reuse.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.key_reuse</span></code> module</a></li>
<li class="toctree-l3"><a class="reference internal" href="../../../../jax.experimental.mesh_utils.html"><code class="docutils literal notranslate"><span class="pre">jax.experimental.mesh_utils</span></code> module</a></li>
</ul>
</li>
<li class="toctree-l2"><a class="reference internal" href="../../../../jax.lib.html"><code class="docutils literal notranslate"><span class="pre">jax.lib</span></code> module</a></li>
</ul>
</li>
</ul>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="../../../../changelog.html">Change log</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../../../glossary.html">JAX Glossary of Terms</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">


<a href="https://github.com/google/jax" target="_blank"
   class="btn btn-sm btn-source-repository-button"
   title="Source repository"
   data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>

</a>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>

</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1></h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <h1>Source code for jax._src.lax.parallel</h1><div class="highlight"><pre>
<span></span><span class="c1"># Copyright 2019 The JAX Authors.</span>
<span class="c1">#</span>
<span class="c1"># Licensed under the Apache License, Version 2.0 (the &quot;License&quot;);</span>
<span class="c1"># you may not use this file except in compliance with the License.</span>
<span class="c1"># You may obtain a copy of the License at</span>
<span class="c1">#</span>
<span class="c1">#     https://www.apache.org/licenses/LICENSE-2.0</span>
<span class="c1">#</span>
<span class="c1"># Unless required by applicable law or agreed to in writing, software</span>
<span class="c1"># distributed under the License is distributed on an &quot;AS IS&quot; BASIS,</span>
<span class="c1"># WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.</span>
<span class="c1"># See the License for the specific language governing permissions and</span>
<span class="c1"># limitations under the License.</span>
<span class="sd">&quot;&quot;&quot;</span>
<span class="sd">Parallelization primitives.</span>
<span class="sd">&quot;&quot;&quot;</span>

<span class="kn">from</span> <span class="nn">__future__</span> <span class="kn">import</span> <span class="n">annotations</span>

<span class="kn">from</span> <span class="nn">collections.abc</span> <span class="kn">import</span> <span class="n">Sequence</span>
<span class="kn">from</span> <span class="nn">functools</span> <span class="kn">import</span> <span class="n">partial</span>
<span class="kn">import</span> <span class="nn">itertools</span>
<span class="kn">import</span> <span class="nn">math</span>
<span class="kn">import</span> <span class="nn">string</span>

<span class="kn">from</span> <span class="nn">jax</span> <span class="kn">import</span> <span class="n">tree_util</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">core</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">dtypes</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">sharding_impls</span>
<span class="kn">from</span> <span class="nn">jax._src</span> <span class="kn">import</span> <span class="n">util</span>
<span class="kn">from</span> <span class="nn">jax._src.core</span> <span class="kn">import</span> <span class="n">AxisName</span><span class="p">,</span> <span class="n">ShapedArray</span><span class="p">,</span> <span class="n">raise_to_shaped</span>
<span class="kn">from</span> <span class="nn">jax._src.interpreters</span> <span class="kn">import</span> <span class="n">ad</span>
<span class="kn">from</span> <span class="nn">jax._src.interpreters</span> <span class="kn">import</span> <span class="n">batching</span>
<span class="kn">from</span> <span class="nn">jax._src.interpreters</span> <span class="kn">import</span> <span class="n">mlir</span>
<span class="kn">from</span> <span class="nn">jax._src.interpreters</span> <span class="kn">import</span> <span class="n">pxla</span>
<span class="kn">from</span> <span class="nn">jax._src.lax</span> <span class="kn">import</span> <span class="n">lax</span>
<span class="kn">from</span> <span class="nn">jax._src.lax</span> <span class="kn">import</span> <span class="n">slicing</span>
<span class="kn">from</span> <span class="nn">jax._src.lib.mlir</span> <span class="kn">import</span> <span class="n">ir</span>
<span class="kn">from</span> <span class="nn">jax._src.lib.mlir.dialects</span> <span class="kn">import</span> <span class="n">hlo</span>
<span class="kn">from</span> <span class="nn">jax._src.numpy</span> <span class="kn">import</span> <span class="n">lax_numpy</span>
<span class="kn">from</span> <span class="nn">jax._src.util</span> <span class="kn">import</span> <span class="p">(</span><span class="n">canonicalize_axis</span><span class="p">,</span> <span class="n">moveaxis</span><span class="p">,</span> <span class="n">safe_map</span><span class="p">,</span> <span class="n">safe_zip</span><span class="p">,</span>
                           <span class="n">unzip2</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="n">unsafe_map</span><span class="p">,</span> <span class="nb">map</span> <span class="o">=</span> <span class="nb">map</span><span class="p">,</span> <span class="n">safe_map</span>  <span class="c1"># type: ignore</span>


<span class="c1">### parallel traceables</span>

<div class="viewcode-block" id="psum">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.psum.html#jax.lax.psum">[docs]</a>
<span class="k">def</span> <span class="nf">psum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Compute an all-reduce sum on ``x`` over the pmapped axis ``axis_name``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  Inputs of boolean dtype are converted to integers before the reduction.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would perform psums over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` representing the result of an</span>
<span class="sd">    all-reduce sum along the axis ``axis_name``.</span>

<span class="sd">  Examples:</span>
<span class="sd">    For example, with 4 XLA devices available:</span>

<span class="sd">    &gt;&gt;&gt; x = np.arange(4)</span>
<span class="sd">    &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">    &gt;&gt;&gt; print(y)</span>
<span class="sd">    [6 6 6 6]</span>
<span class="sd">    &gt;&gt;&gt; y = jax.pmap(lambda x: x / jax.lax.psum(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">    &gt;&gt;&gt; print(y)</span>
<span class="sd">    [0.         0.16666667 0.33333334 0.5       ]</span>

<span class="sd">    Suppose we want to perform ``psum`` among two groups, one with ``device0`` and ``device1``, the other with ``device2`` and ``device3``,</span>

<span class="sd">    &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum(x, &#39;i&#39;, axis_index_groups=[[0, 1], [2, 3]]), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">    &gt;&gt;&gt; print(y)</span>
<span class="sd">    [1 1 5 5]</span>

<span class="sd">    An example using 2D-shaped x. Each row is data from one device.</span>

<span class="sd">    &gt;&gt;&gt; x = np.arange(16).reshape(4, 4)</span>
<span class="sd">    &gt;&gt;&gt; print(x)</span>
<span class="sd">    [[ 0  1  2  3]</span>
<span class="sd">     [ 4  5  6  7]</span>
<span class="sd">     [ 8  9 10 11]</span>
<span class="sd">     [12 13 14 15]]</span>

<span class="sd">    Full ``psum`` across all devices:</span>

<span class="sd">    &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">    &gt;&gt;&gt; print(y)</span>
<span class="sd">    [[24 28 32 36]</span>
<span class="sd">     [24 28 32 36]</span>
<span class="sd">     [24 28 32 36]</span>
<span class="sd">     [24 28 32 36]]</span>

<span class="sd">    Perform ``psum`` among two groups:</span>

<span class="sd">    &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum(x, &#39;i&#39;, axis_index_groups=[[0, 1], [2, 3]]), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">    &gt;&gt;&gt; print(y)</span>
<span class="sd">    [[ 4  6  8 10]</span>
<span class="sd">     [ 4  6  8 10]</span>
<span class="sd">     [20 22 24 26]</span>
<span class="sd">     [20 22 24 26]]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups only supported for sums over just named axes&quot;</span><span class="p">)</span>
  <span class="n">_validate_reduce_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">leaves</span><span class="p">,</span> <span class="n">treedef</span> <span class="o">=</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">leaves</span> <span class="o">=</span> <span class="p">[</span><span class="n">lax</span><span class="o">.</span><span class="n">convert_element_type</span><span class="p">(</span><span class="n">l</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">)</span>
            <span class="k">if</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">l</span><span class="p">)</span> <span class="o">==</span> <span class="n">np</span><span class="o">.</span><span class="n">bool_</span> <span class="k">else</span> <span class="n">l</span> <span class="k">for</span> <span class="n">l</span> <span class="ow">in</span> <span class="n">leaves</span><span class="p">]</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">out_flat</span> <span class="o">=</span> <span class="n">psum_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
      <span class="o">*</span><span class="n">leaves</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axis_name</span><span class="p">),</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_unflatten</span><span class="p">(</span><span class="n">treedef</span><span class="p">,</span> <span class="n">out_flat</span><span class="p">)</span></div>


<div class="viewcode-block" id="pmean">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pmean.html#jax.lax.pmean">[docs]</a>
<span class="k">def</span> <span class="nf">pmean</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Compute an all-reduce mean on ``x`` over the pmapped axis ``axis_name``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would perform pmeans over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and on TPUs all groups must be the same size.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` representing the result of an</span>
<span class="sd">    all-reduce mean along the axis ``axis_name``.</span>

<span class="sd">  For example, with 4 XLA devices available:</span>

<span class="sd">  &gt;&gt;&gt; x = np.arange(4)</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.pmean(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [1.5 1.5 1.5 1.5]</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(lambda x: x / jax.lax.pmean(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [0.        0.6666667 1.3333334 2.       ]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">n</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="k">lambda</span> <span class="n">v</span><span class="p">:</span> <span class="n">v</span> <span class="o">/</span> <span class="n">n</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="pmax">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pmax.html#jax.lax.pmax">[docs]</a>
<span class="k">def</span> <span class="nf">pmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Compute an all-reduce max on ``x`` over the pmapped axis ``axis_name``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would perform pmaxes over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and on TPUs all groups must be the same size.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` representing the result of an</span>
<span class="sd">    all-reduce max along the axis ``axis_name``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups only supported for sums over just named axes&quot;</span><span class="p">)</span>
  <span class="n">_validate_reduce_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">leaves</span><span class="p">,</span> <span class="n">treedef</span> <span class="o">=</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">out_flat</span> <span class="o">=</span> <span class="n">pmax_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">leaves</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
                         <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_unflatten</span><span class="p">(</span><span class="n">treedef</span><span class="p">,</span> <span class="n">out_flat</span><span class="p">)</span></div>


<div class="viewcode-block" id="pmin">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pmin.html#jax.lax.pmin">[docs]</a>
<span class="k">def</span> <span class="nf">pmin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Compute an all-reduce min on ``x`` over the pmapped axis ``axis_name``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would perform pmins over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and on TPUs all groups must be the same size.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` representing the result of an</span>
<span class="sd">    all-reduce min along the axis ``axis_name``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">)</span> <span class="ow">and</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups only supported for sums over just named axes&quot;</span><span class="p">)</span>
  <span class="n">_validate_reduce_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">leaves</span><span class="p">,</span> <span class="n">treedef</span> <span class="o">=</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">out_flat</span> <span class="o">=</span> <span class="n">pmin_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">leaves</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
                         <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_unflatten</span><span class="p">(</span><span class="n">treedef</span><span class="p">,</span> <span class="n">out_flat</span><span class="p">)</span></div>


<span class="c1"># TODO(mattjj): add a pargmin_p, or add named axis support to lax.argmin_p</span>
<span class="k">def</span> <span class="nf">pargmin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pargmin only accepts a single axis, got </span><span class="si">{</span><span class="n">axis_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_axis_index_of_val</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pmin</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">),</span> <span class="n">axis_name</span><span class="p">)</span>

<span class="c1"># TODO(mattjj): add a pargmax_p, or add named axis support to lax.argmax_p</span>
<span class="k">def</span> <span class="nf">pargmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">TypeError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;pargmin only accepts a single axis, got </span><span class="si">{</span><span class="n">axis_name</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">_axis_index_of_val</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">pmax</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">),</span> <span class="n">axis_name</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_axis_index_of_val</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">val</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">axis_index</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
  <span class="n">validx</span> <span class="o">=</span> <span class="n">lax_numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">val</span> <span class="o">==</span> <span class="n">x</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">dtypes</span><span class="o">.</span><span class="n">iinfo</span><span class="p">(</span><span class="n">dtypes</span><span class="o">.</span><span class="n">dtype</span><span class="p">(</span><span class="n">idx</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">pmin</span><span class="p">(</span><span class="n">validx</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_validate_reduce_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span>
  <span class="n">axis_space</span> <span class="o">=</span> <span class="nb">range</span><span class="p">(</span><span class="nb">sum</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">axis_index_groups</span><span class="p">))</span>
  <span class="k">if</span> <span class="p">{</span><span class="n">i</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">axis_index_groups</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">g</span><span class="p">}</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="n">axis_space</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups must cover all indices exactly once&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span>
  <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">))</span>


<span class="k">def</span> <span class="nf">pbroadcast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Perform a collective broadcast and replicate from ``source``.</span>

<span class="sd">  This is equivalent to</span>
<span class="sd">  ```</span>
<span class="sd">  def pbroadcast(x, axis_name, source):</span>
<span class="sd">    masked = jnp.where(axis_index(axis_name) == source, x, zeros_like(x))</span>
<span class="sd">    return psum(masked, axis_name)</span>
<span class="sd">  ```</span>
<span class="sd">  but implemented in a hardware optimized way.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  This function is an analog of the CollectiveBroadcast HLO.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    source: int, representing which index into ``axis_name`` that should be copied.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with ``x`` being copied from the ``source`` index slice of ``axis_name``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
      <span class="n">partial</span><span class="p">(</span><span class="n">pbroadcast_p</span><span class="o">.</span><span class="n">bind</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">),</span> <span class="n">x</span><span class="p">)</span>


<div class="viewcode-block" id="ppermute">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.ppermute.html#jax.lax.ppermute">[docs]</a>
<span class="k">def</span> <span class="nf">ppermute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">perm</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Perform a collective permutation according to the permutation ``perm``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  This function is an analog of the CollectivePermute HLO.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    perm: list of pairs of ints, representing</span>
<span class="sd">      ``(source_index, destination_index)``</span>
<span class="sd">      pairs that encode how the mapped axis named ``axis_name`` should be</span>
<span class="sd">      shuffled. The integer values are treated as indices into the mapped axis</span>
<span class="sd">      ``axis_name``. Any two pairs should not have the same source index or the</span>
<span class="sd">      same destination index. For each index of the axis ``axis_name`` that does</span>
<span class="sd">      not correspond to a destination index in ``perm``, the corresponding</span>
<span class="sd">      values in the result are filled with zeros of the appropriate type.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` with slices along the axis</span>
<span class="sd">    ``axis_name`` gathered from ``x`` according to the permutation ``perm``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span>
      <span class="n">partial</span><span class="p">(</span><span class="n">ppermute_p</span><span class="o">.</span><span class="n">bind</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
              <span class="n">perm</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">perm</span><span class="p">))),</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="pshuffle">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pshuffle.html#jax.lax.pshuffle">[docs]</a>
<span class="k">def</span> <span class="nf">pshuffle</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">perm</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Convenience wrapper of jax.lax.ppermute with alternate permutation encoding</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    perm: list of ints encoding sources for the permutation to be applied to</span>
<span class="sd">      the axis named ``axis_name``, so that the output at axis index i</span>
<span class="sd">      comes from the input at axis index perm[i]. Every integer in [0, N) should</span>
<span class="sd">      be included exactly once for axis size N.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x`` with slices along the axis</span>
<span class="sd">    ``axis_name`` gathered from ``x`` according to the permutation ``perm``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="nb">set</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">set</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">perm</span><span class="p">))):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;`perm` does not represent a permutation: </span><span class="si">{</span><span class="n">perm</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ppermute</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">perm</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">perm</span><span class="p">)))))</span></div>



<div class="viewcode-block" id="pswapaxes">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pswapaxes.html#jax.lax.pswapaxes">[docs]</a>
<span class="k">def</span> <span class="nf">pswapaxes</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Swap the pmapped axis ``axis_name`` with the unmapped axis ``axis``.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  The group size of the mapped axis size must be equal to the size of the</span>
<span class="sd">  unmapped axis; that is, we must have</span>
<span class="sd">  ``lax.psum(1, axis_name, axis_index_groups=axis_index_groups) == x.shape[axis]``.</span>
<span class="sd">  By default, when ``axis_index_groups=None``, this encompasses all the devices.</span>

<span class="sd">  This function is a special case of ``all_to_all`` where the pmapped axis of</span>
<span class="sd">  the input is placed at the position ``axis`` in the output. That is, it is</span>
<span class="sd">  equivalent to ``all_to_all(x, axis_name, axis, axis)``.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis: int indicating the unmapped axis of ``x`` to map with the name</span>
<span class="sd">      ``axis_name``.</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would run pswapaxes over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and all groups must be the same size.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the same shape as ``x``.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axis</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span></div>


<div class="viewcode-block" id="all_to_all">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.all_to_all.html#jax.lax.all_to_all">[docs]</a>
<span class="k">def</span> <span class="nf">all_to_all</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">tiled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Materialize the mapped axis and map a different axis.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  In the output, the input mapped axis ``axis_name`` is materialized at the</span>
<span class="sd">  logical axis position ``concat_axis``, and the input unmapped axis at position</span>
<span class="sd">  ``split_axis`` is mapped with the name ``axis_name``.</span>

<span class="sd">  The group size of the mapped axis size must be equal to the size of the</span>
<span class="sd">  unmapped axis; that is, we must have</span>
<span class="sd">  ``lax.psum(1, axis_name, axis_index_groups=axis_index_groups) == x.shape[axis]``.</span>
<span class="sd">  By default, when ``axis_index_groups=None``, this encompasses all the devices.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    split_axis: int indicating the unmapped axis of ``x`` to map with the name</span>
<span class="sd">      ``axis_name``.</span>
<span class="sd">    concat_axis: int indicating the position in the output to materialize the</span>
<span class="sd">      mapped axis of the input with the name ``axis_name``.</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would run all_to_all over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and all groups must be the same size.</span>
<span class="sd">    tiled: when True, all_to_all will divide split_axis into chunks and concatenate</span>
<span class="sd">      them along concat_axis. In particular, no dimensions are added or removed.</span>
<span class="sd">      False by default.</span>

<span class="sd">  Returns:</span>
<span class="sd">    When tiled is False, array(s) with shape given by the expression::</span>

<span class="sd">      np.insert(np.delete(x.shape, split_axis), concat_axis, axis_size)</span>

<span class="sd">    where ``axis_size`` is the size of the mapped axis named ``axis_name`` in</span>
<span class="sd">    the input ``x``, i.e. ``axis_size = lax.psum(1, axis_name)``.</span>

<span class="sd">    Otherwise array with shape similar to the input shape, except with split_axis</span>
<span class="sd">    divided by axis size and concat_axis multiplied by axis size.</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split_axis</span><span class="o">=</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=</span><span class="n">concat_axis</span><span class="p">):</span>
    <span class="n">group_size</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]</span> <span class="o">%</span> <span class="n">group_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;The size of all_to_all split_axis (</span><span class="si">{</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]</span><span class="si">}</span><span class="s2">) &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;has to be divisible by the size of the named axis &quot;</span>
                         <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">axis_name</span><span class="si">}</span><span class="s2"> (</span><span class="si">{</span><span class="n">group_size</span><span class="si">}</span><span class="s2">)&quot;</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">if</span> <span class="n">group_size</span> <span class="o">!=</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]:</span>
        <span class="n">msg</span> <span class="o">=</span> <span class="p">(</span><span class="s2">&quot;all_to_all requires the size of the mapped axis axis_name to &quot;</span>
               <span class="s2">&quot;equal x.shape[split_axis], but they are </span><span class="si">{}</span><span class="s2"> and </span><span class="si">{}</span><span class="s2"> respectively.&quot;</span><span class="p">)</span>
        <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">group_size</span><span class="p">,</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]))</span>
      <span class="k">if</span> <span class="n">split_axis</span> <span class="o">&lt;</span> <span class="n">concat_axis</span><span class="p">:</span>
        <span class="n">concat_axis</span> <span class="o">+=</span> <span class="mi">1</span>  <span class="c1"># concat_axis gives a position _after_ split_axis is removed</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">concat_axis</span><span class="p">,))</span>  <span class="c1"># insert the new axis</span>
      <span class="k">elif</span> <span class="n">split_axis</span> <span class="o">==</span> <span class="n">concat_axis</span><span class="p">:</span>
        <span class="k">pass</span>
      <span class="k">else</span><span class="p">:</span>  <span class="c1"># concat_axis &lt; split_axis</span>
        <span class="n">x</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">concat_axis</span><span class="p">,))</span>  <span class="c1"># insert the new axis</span>
        <span class="n">split_axis</span> <span class="o">+=</span> <span class="mi">1</span>   <span class="c1"># we have a new axis before split_axis now</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">all_to_all_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">split_axis</span><span class="o">=</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=</span><span class="n">concat_axis</span><span class="p">,</span>
                               <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
                               <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
                               <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
    <span class="k">if</span> <span class="ow">not</span> <span class="n">tiled</span> <span class="ow">and</span> <span class="n">split_axis</span> <span class="o">!=</span> <span class="n">concat_axis</span><span class="p">:</span>
      <span class="n">result</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span><span class="n">result</span><span class="p">,</span> <span class="p">(</span><span class="n">split_axis</span><span class="p">,))</span>
    <span class="k">return</span> <span class="n">result</span>

  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<div class="viewcode-block" id="axis_index">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.axis_index.html#jax.lax.axis_index">[docs]</a>
<span class="k">def</span> <span class="nf">axis_index</span><span class="p">(</span><span class="n">axis_name</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Return the index along the mapped axis ``axis_name``.</span>

<span class="sd">  Args:</span>
<span class="sd">    axis_name: hashable Python object used to name the mapped axis.</span>

<span class="sd">  Returns:</span>
<span class="sd">    An integer representing the index.</span>

<span class="sd">  For example, with 8 XLA devices available:</span>

<span class="sd">  &gt;&gt;&gt; from functools import partial</span>
<span class="sd">  &gt;&gt;&gt; @partial(jax.pmap, axis_name=&#39;i&#39;)</span>
<span class="sd">  ... def f(_):</span>
<span class="sd">  ...   return lax.axis_index(&#39;i&#39;)</span>
<span class="sd">  ...</span>
<span class="sd">  &gt;&gt;&gt; f(np.zeros(4))</span>
<span class="sd">  Array([0, 1, 2, 3], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt; f(np.zeros(8))</span>
<span class="sd">  Array([0, 1, 2, 3, 4, 5, 6, 7], dtype=int32)</span>
<span class="sd">  &gt;&gt;&gt; @partial(jax.pmap, axis_name=&#39;i&#39;)</span>
<span class="sd">  ... @partial(jax.pmap, axis_name=&#39;j&#39;)</span>
<span class="sd">  ... def f(_):</span>
<span class="sd">  ...   return lax.axis_index(&#39;i&#39;), lax.axis_index(&#39;j&#39;)</span>
<span class="sd">  ...</span>
<span class="sd">  &gt;&gt;&gt; x, y = f(np.zeros((4, 2)))</span>
<span class="sd">  &gt;&gt;&gt; print(x)</span>
<span class="sd">  [[0 0]</span>
<span class="sd">  [1 1]</span>
<span class="sd">  [2 2]</span>
<span class="sd">  [3 3]]</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [[0 1]</span>
<span class="sd">  [0 1]</span>
<span class="sd">  [0 1]</span>
<span class="sd">  [0 1]]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="k">return</span> <span class="n">axis_index_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">)</span></div>



<div class="viewcode-block" id="pdot">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.pdot.html#jax.lax.pdot">[docs]</a>
<span class="k">def</span> <span class="nf">pdot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="o">=</span><span class="p">((),</span> <span class="p">()),</span> <span class="n">pos_batch</span><span class="o">=</span><span class="p">((),</span> <span class="p">()),</span>
         <span class="n">precision</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">pos_contract</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">))</span>
  <span class="n">pos_batch</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">pdot_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axis_name</span><span class="p">),</span>
                     <span class="n">pos_contract</span><span class="o">=</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="o">=</span><span class="n">pos_batch</span><span class="p">,</span>
                     <span class="n">precision</span><span class="o">=</span><span class="n">lax</span><span class="o">.</span><span class="n">canonicalize_precision</span><span class="p">(</span><span class="n">precision</span><span class="p">))</span></div>



<span class="k">def</span> <span class="nf">xeinsum</span><span class="p">(</span><span class="n">spec</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="o">*</span><span class="n">operands</span><span class="p">):</span>
  <span class="n">in_spec</span><span class="p">,</span> <span class="n">out_spec</span> <span class="o">=</span> <span class="n">spec</span><span class="o">.</span><span class="n">split</span><span class="p">(</span><span class="s1">&#39;-&gt;&#39;</span><span class="p">)</span>
  <span class="n">all_in_subs</span><span class="p">,</span> <span class="n">all_in_named</span> <span class="o">=</span> <span class="n">unzip2</span><span class="p">(</span><span class="n">XeinsumSpecParser</span><span class="p">(</span><span class="n">in_spec</span><span class="p">)</span><span class="o">.</span><span class="n">parse_args</span><span class="p">())</span>
  <span class="p">(</span><span class="n">out_subs</span><span class="p">,</span> <span class="n">out_named</span><span class="p">),</span> <span class="o">=</span> <span class="n">XeinsumSpecParser</span><span class="p">(</span><span class="n">out_spec</span><span class="p">)</span><span class="o">.</span><span class="n">parse_args</span><span class="p">()</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span> <span class="o">!=</span> <span class="nb">len</span><span class="p">(</span><span class="n">all_in_named</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Expecting the same number of argument specs in the &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;subscript (</span><span class="si">{</span><span class="n">in_spec</span><span class="si">}</span><span class="s2">) as the number of operands. But got &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">all_in_named</span><span class="p">)</span><span class="si">}</span><span class="s2"> argument specs for &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span><span class="si">}</span><span class="s2"> operands&quot;</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">2</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Only one or two operands are supported. &quot;</span>
                              <span class="sa">f</span><span class="s2">&quot;But got </span><span class="si">{</span><span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span><span class="si">}</span><span class="s2"> operands&quot;</span><span class="p">)</span>

  <span class="c1"># output subs and named axes must appear in at least one of the inputs.</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">out_named</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_in_named</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Found named axes &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">out_named</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_in_named</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                     <span class="s2">&quot;appearing in the output spec but not in the input&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">set</span><span class="p">(</span><span class="n">out_subs</span><span class="p">)</span><span class="o">.</span><span class="n">issubset</span><span class="p">(</span><span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_in_subs</span><span class="p">)):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Found subscript(s) &quot;</span>
                     <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="nb">set</span><span class="p">(</span><span class="n">out_subs</span><span class="p">)</span><span class="w"> </span><span class="o">-</span><span class="w"> </span><span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span><span class="o">*</span><span class="n">all_in_subs</span><span class="p">)</span><span class="si">}</span><span class="s2"> &quot;</span>
                     <span class="s2">&quot;appearing in the output spec but not in the input&quot;</span><span class="p">)</span>

  <span class="n">xs</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="n">in_subs</span><span class="p">,</span> <span class="n">in_named</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">safe_zip</span><span class="p">(</span><span class="n">all_in_subs</span><span class="p">,</span> <span class="n">all_in_named</span><span class="p">)):</span>
    <span class="c1"># if a subscript axis appears only in one input and not the output, reduce!</span>
    <span class="n">other_named</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="o">*</span><span class="p">[</span><span class="n">named</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">named</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_in_named</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">idx</span><span class="p">])</span>
    <span class="n">other_subs</span> <span class="o">=</span> <span class="nb">set</span><span class="p">()</span><span class="o">.</span><span class="n">union</span><span class="p">(</span>  <span class="c1"># type: ignore</span>
        <span class="o">*</span><span class="p">[</span><span class="n">subs</span> <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">subs</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">all_in_subs</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">idx</span><span class="p">])</span>

    <span class="n">subs_reduce</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">in_subs</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="o">*</span><span class="n">out_subs</span><span class="p">,</span> <span class="o">*</span><span class="n">other_subs</span><span class="p">})</span>
    <span class="n">subs_reduce_axes</span> <span class="o">=</span> <span class="p">[</span><span class="n">in_subs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">subs_reduce</span><span class="p">]</span>
    <span class="n">named_reduce_axes</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">in_named</span><span class="p">)</span> <span class="o">-</span> <span class="p">{</span><span class="o">*</span><span class="n">out_named</span><span class="p">,</span> <span class="o">*</span><span class="n">other_named</span><span class="p">})</span>

    <span class="k">if</span> <span class="n">subs_reduce_axes</span> <span class="ow">or</span> <span class="n">named_reduce_axes</span><span class="p">:</span>
      <span class="n">xs</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="n">xs</span><span class="p">[</span><span class="n">idx</span><span class="p">],</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">subs_reduce_axes</span> <span class="o">+</span> <span class="n">named_reduce_axes</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">subs_reduce_axes</span><span class="p">,</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
        <span class="k">del</span> <span class="n">all_in_subs</span><span class="p">[</span><span class="n">idx</span><span class="p">][</span><span class="n">i</span><span class="p">]</span>
      <span class="k">for</span> <span class="n">named_axis</span> <span class="ow">in</span> <span class="n">named_reduce_axes</span><span class="p">:</span>
        <span class="n">all_in_named</span><span class="p">[</span><span class="n">idx</span><span class="p">]</span><span class="o">.</span><span class="n">remove</span><span class="p">(</span><span class="n">named_axis</span><span class="p">)</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">xs</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">operands</span><span class="p">)</span> <span class="o">==</span> <span class="mi">2</span><span class="p">:</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">xs</span>
    <span class="n">lhs_subs</span><span class="p">,</span> <span class="n">rhs_subs</span> <span class="o">=</span> <span class="n">all_in_subs</span>
    <span class="n">lhs_named</span><span class="p">,</span> <span class="n">rhs_named</span> <span class="o">=</span> <span class="n">all_in_named</span>

    <span class="c1"># if a named axis appears in both inputs and not the output, contract!</span>
    <span class="n">named_contract</span> <span class="o">=</span> <span class="nb">list</span><span class="p">((</span><span class="nb">set</span><span class="p">(</span><span class="n">lhs_named</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">rhs_named</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">out_named</span><span class="p">))</span>

    <span class="c1"># if a subscript appears in both inputs and not the outputs, contract!</span>
    <span class="n">subs_contract</span> <span class="o">=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">lhs_subs</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">rhs_subs</span><span class="p">))</span> <span class="o">-</span> <span class="nb">set</span><span class="p">(</span><span class="n">out_subs</span><span class="p">)</span>

    <span class="n">pos_contract</span> <span class="o">=</span> <span class="n">unzip2</span><span class="p">((</span><span class="n">lhs_subs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">rhs_subs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">n</span><span class="p">))</span>
                          <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">subs_contract</span><span class="p">)</span>

    <span class="c1"># if a subscript appears in both inputs _and_ the outputs, batch!</span>
    <span class="n">subs_batch</span> <span class="o">=</span> <span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">lhs_subs</span><span class="p">)</span> <span class="o">&amp;</span> <span class="nb">set</span><span class="p">(</span><span class="n">rhs_subs</span><span class="p">))</span> <span class="o">-</span> <span class="n">subs_contract</span>
    <span class="n">pos_batch</span> <span class="o">=</span> <span class="n">unzip2</span><span class="p">((</span><span class="n">lhs_subs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">n</span><span class="p">),</span> <span class="n">rhs_subs</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">n</span><span class="p">))</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">subs_batch</span><span class="p">)</span>

    <span class="k">return</span> <span class="n">pdot</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">named_contract</span><span class="p">,</span>
                <span class="n">pos_contract</span><span class="o">=</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="o">=</span><span class="n">pos_batch</span><span class="p">)</span>


<span class="k">class</span> <span class="nc">XeinsumSpecParser</span><span class="p">:</span>
  <span class="n">spec</span><span class="p">:</span> <span class="nb">str</span>
  <span class="n">pos</span><span class="p">:</span> <span class="nb">int</span>

  <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">spec</span><span class="p">:</span> <span class="nb">str</span><span class="p">):</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">spec</span> <span class="o">=</span> <span class="n">spec</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="mi">0</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">eof</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">)</span>

  <span class="nd">@property</span>
  <span class="k">def</span> <span class="nf">cur</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">]</span>

  <span class="k">def</span> <span class="nf">parse_subscript</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cur</span> <span class="ow">in</span> <span class="n">string</span><span class="o">.</span><span class="n">ascii_lowercase</span><span class="p">:</span>
      <span class="n">out</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">cur</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="kc">True</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">None</span><span class="p">,</span> <span class="kc">False</span>

  <span class="k">def</span> <span class="nf">parse_axis_name</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="k">try</span><span class="p">:</span>
      <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;}&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
      <span class="k">assert</span> <span class="kc">False</span>

    <span class="k">try</span><span class="p">:</span>
      <span class="n">end</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">,</span> <span class="n">end</span><span class="p">)</span>
    <span class="k">except</span> <span class="ne">ValueError</span><span class="p">:</span>
      <span class="k">pass</span>

    <span class="n">axis_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">spec</span><span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">pos</span><span class="p">:</span><span class="n">end</span><span class="p">]</span>
    <span class="k">assert</span> <span class="n">axis_name</span>
    <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">=</span> <span class="n">end</span>
    <span class="k">return</span> <span class="n">axis_name</span>

  <span class="k">def</span> <span class="nf">maybe_take</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">char</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">on_eof</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="kc">False</span><span class="p">):</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">:</span>
      <span class="k">return</span> <span class="n">on_eof</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">cur</span> <span class="o">==</span> <span class="n">char</span><span class="p">:</span>
      <span class="bp">self</span><span class="o">.</span><span class="n">pos</span> <span class="o">+=</span> <span class="mi">1</span>
      <span class="k">return</span> <span class="kc">True</span>

  <span class="k">def</span> <span class="nf">parse_arg</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">subscripts</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">names</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">:</span>
      <span class="n">subscript</span><span class="p">,</span> <span class="n">cont</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_subscript</span><span class="p">()</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">cont</span><span class="p">:</span> <span class="k">break</span>
      <span class="n">subscripts</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">subscript</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">:</span>
      <span class="k">return</span> <span class="kc">False</span><span class="p">,</span> <span class="p">(</span><span class="n">subscripts</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>
    <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">maybe_take</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">):</span>
      <span class="k">return</span> <span class="kc">True</span><span class="p">,</span> <span class="p">(</span><span class="n">subscripts</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">maybe_take</span><span class="p">(</span><span class="s1">&#39;{&#39;</span><span class="p">)</span>
      <span class="n">first</span> <span class="o">=</span> <span class="kc">True</span>
      <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">maybe_take</span><span class="p">(</span><span class="s1">&#39;}&#39;</span><span class="p">):</span>
        <span class="k">if</span> <span class="ow">not</span> <span class="n">first</span><span class="p">:</span>
          <span class="k">assert</span> <span class="bp">self</span><span class="o">.</span><span class="n">maybe_take</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">)</span>
        <span class="n">first</span> <span class="o">=</span> <span class="kc">False</span>
        <span class="k">if</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">:</span>
          <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;Unterminated named axis brace&quot;</span><span class="p">)</span>
        <span class="n">axis_name</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_axis_name</span><span class="p">()</span>
        <span class="n">names</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
      <span class="k">return</span> <span class="bp">self</span><span class="o">.</span><span class="n">maybe_take</span><span class="p">(</span><span class="s1">&#39;,&#39;</span><span class="p">,</span> <span class="kc">False</span><span class="p">),</span> <span class="p">(</span><span class="n">subscripts</span><span class="p">,</span> <span class="n">names</span><span class="p">)</span>

  <span class="k">def</span> <span class="nf">parse_args</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
    <span class="n">arg_specs</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">cont</span> <span class="o">=</span> <span class="kc">True</span>
    <span class="k">while</span> <span class="ow">not</span> <span class="bp">self</span><span class="o">.</span><span class="n">eof</span><span class="p">:</span>
      <span class="n">cont</span><span class="p">,</span> <span class="n">result</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">parse_arg</span><span class="p">()</span>
      <span class="n">arg_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">result</span><span class="p">)</span>
    <span class="k">if</span> <span class="n">cont</span><span class="p">:</span>
      <span class="n">arg_specs</span><span class="o">.</span><span class="n">append</span><span class="p">(([],</span> <span class="p">[]))</span>
    <span class="k">return</span> <span class="n">arg_specs</span>


<span class="k">def</span> <span class="nf">pgather</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="p">:</span> <span class="nb">int</span> <span class="o">|</span> <span class="n">AxisName</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Uses the last positional axis of idx to index into src&#39;s axes.&quot;&quot;&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axes</span> <span class="o">=</span> <span class="p">(</span><span class="n">axes</span><span class="p">,)</span>
  <span class="c1"># TODO: Canonicalize exes!</span>
  <span class="k">return</span> <span class="n">pgather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axes</span><span class="p">))</span>


<span class="c1">### parallel primitives</span>

<span class="k">def</span> <span class="nf">_subst_all_names_in_param</span><span class="p">(</span>
    <span class="n">pname</span><span class="p">:</span> <span class="nb">str</span><span class="p">,</span> <span class="n">params</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">ParamDict</span><span class="p">,</span> <span class="n">subst</span><span class="p">:</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisSubst</span><span class="p">,</span> <span class="n">traverse</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">core</span><span class="o">.</span><span class="n">ParamDict</span><span class="p">:</span>
  <span class="n">axis_name</span> <span class="o">=</span> <span class="n">params</span><span class="p">[</span><span class="n">pname</span><span class="p">]</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">result</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">params</span><span class="p">)</span>
  <span class="n">result</span><span class="p">[</span><span class="n">pname</span><span class="p">]</span> <span class="o">=</span> <span class="nb">sum</span><span class="p">(((</span><span class="n">name</span><span class="p">,)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">name</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">subst</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
                       <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">),</span>
                      <span class="p">())</span>
  <span class="k">return</span> <span class="n">result</span>

<span class="k">def</span> <span class="nf">_reduction_with_positional_batcher</span><span class="p">(</span><span class="n">prim</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span>
    <span class="n">transform_unmapped</span><span class="p">,</span> <span class="n">transform_mapped</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups not supported in vmap collectives. &quot;</span>
                              <span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="n">vals_in</span> <span class="o">=</span> <span class="p">[</span><span class="n">val</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span> <span class="ow">or</span> <span class="n">d</span> <span class="o">==</span> <span class="mi">0</span> <span class="k">else</span> <span class="n">_moveaxis</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">val</span><span class="p">)</span>
             <span class="k">for</span> <span class="n">val</span><span class="p">,</span> <span class="n">d</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">)]</span>
  <span class="n">mapped_vals_in</span><span class="p">,</span> <span class="n">unmapped_vals_in</span> <span class="o">=</span> <span class="n">partitioned_vals_in</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="n">mapped_idxs</span><span class="p">,</span> <span class="n">unmapped_idxs</span> <span class="o">=</span> <span class="n">partitioned_idxs</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="p">(</span><span class="n">val</span><span class="p">,</span> <span class="n">d</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">)):</span>
    <span class="n">partitioned_vals_in</span><span class="p">[</span><span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">val</span><span class="p">)</span>
    <span class="n">partitioned_idxs</span><span class="p">[</span><span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">i</span><span class="p">)</span>
  <span class="n">vals_out</span> <span class="o">=</span> <span class="p">[</span><span class="kc">None</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vals_in</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">unmapped_vals_in</span><span class="p">:</span>
    <span class="n">unmapped_axes</span><span class="p">,</span> <span class="n">unmapped_vals_in</span> <span class="o">=</span> <span class="n">transform_unmapped</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">unmapped_vals_in</span><span class="p">)</span>
    <span class="n">unmapped_vals_out</span> <span class="o">=</span> <span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">unmapped_vals_in</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">unmapped_axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">unmapped_idxs</span><span class="p">,</span> <span class="n">unmapped_vals_out</span><span class="p">):</span>
      <span class="n">vals_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
  <span class="k">if</span> <span class="n">mapped_vals_in</span><span class="p">:</span>
    <span class="n">mapped_axes</span><span class="p">,</span> <span class="n">mapped_vals_in</span> <span class="o">=</span> <span class="n">transform_mapped</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">mapped_vals_in</span><span class="p">)</span>
    <span class="n">mapped_vals_out</span> <span class="o">=</span> <span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">mapped_vals_in</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">mapped_axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">val</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">mapped_idxs</span><span class="p">,</span> <span class="n">mapped_vals_out</span><span class="p">):</span>
      <span class="n">vals_out</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">val</span>
  <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="n">v</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">vals_out</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">vals_out</span>

<span class="k">def</span> <span class="nf">_reduction_batcher</span><span class="p">(</span><span class="n">prim</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">prim</span><span class="o">.</span><span class="n">multiple_results</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">any</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">),</span> <span class="n">dims_in</span>
  <span class="n">vals_out</span> <span class="o">=</span> <span class="n">_reduction_with_positional_batcher</span><span class="p">(</span>
      <span class="n">prim</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="k">lambda</span> <span class="n">d</span><span class="p">,</span> <span class="n">d_vals_in</span><span class="p">:</span> <span class="p">(</span><span class="n">axes</span><span class="p">,</span> <span class="n">d_vals_in</span><span class="p">),</span>
      <span class="k">lambda</span> <span class="n">d</span><span class="p">,</span> <span class="n">d_vals_in</span><span class="p">:</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">d</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span> <span class="n">axis</span>
                                  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">),</span>
                            <span class="n">d_vals_in</span><span class="p">))</span>
  <span class="c1"># _reduction_with_positional_batcher moves all map dims to 0</span>
  <span class="k">return</span> <span class="n">vals_out</span><span class="p">,</span> <span class="p">[</span><span class="n">d</span> <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span> <span class="k">else</span> <span class="mi">0</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">dims_in</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">_batched_reduction_collective</span><span class="p">(</span>
    <span class="n">prim</span><span class="p">,</span> <span class="n">if_unmapped</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span>
    <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">prim</span><span class="o">.</span><span class="n">multiple_results</span>
  <span class="k">assert</span> <span class="n">frame_name</span> <span class="ow">in</span> <span class="n">axes</span>
  <span class="c1"># Note that we have a choice here. We can either unfuse the reduction into one</span>
  <span class="c1"># that handles the batched dims and then another one that handles the rest.</span>
  <span class="c1"># Alternatively, we can keep the dimension reduction fused with the rest, but</span>
  <span class="c1"># we have to split the primitive into one for unmapped inputs and another</span>
  <span class="c1"># one for mapped, because they differ in their `axes` parameter.</span>
  <span class="c1"># We choose the second strategy here.</span>
  <span class="n">vals_out</span> <span class="o">=</span> <span class="n">_reduction_with_positional_batcher</span><span class="p">(</span>
      <span class="n">prim</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="k">lambda</span> <span class="n">d</span><span class="p">,</span> <span class="n">d_vals_in</span><span class="p">:</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">!=</span> <span class="n">frame_name</span><span class="p">),</span>
                            <span class="p">[</span><span class="n">if_unmapped</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">v</span> <span class="ow">in</span> <span class="n">d_vals_in</span><span class="p">]),</span>
      <span class="k">lambda</span> <span class="n">d</span><span class="p">,</span> <span class="n">d_vals_in</span><span class="p">:</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">axis</span> <span class="o">&gt;=</span> <span class="n">d</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span>
                                  <span class="n">axis</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">!=</span> <span class="n">frame_name</span> <span class="k">else</span>
                                  <span class="n">d</span>
                                  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">),</span>
                            <span class="n">d_vals_in</span><span class="p">))</span>
  <span class="k">return</span> <span class="n">vals_out</span><span class="p">,</span> <span class="p">[</span><span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">]</span> <span class="o">*</span> <span class="nb">len</span><span class="p">(</span><span class="n">vals_out</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_replica_groups</span><span class="p">(</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">pxla</span><span class="o">.</span><span class="n">axis_groups</span><span class="p">(</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">replica_groups</span> <span class="o">=</span> <span class="p">[[</span><span class="n">axis_group</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">axis_index_group</span><span class="p">]</span>
                      <span class="k">for</span> <span class="n">axis_group</span> <span class="ow">in</span> <span class="n">replica_groups</span>
                      <span class="k">for</span> <span class="n">axis_index_group</span> <span class="ow">in</span> <span class="n">axis_index_groups</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">replica_groups</span>

<span class="k">def</span> <span class="nf">_replica_groups_hlo</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">:</span> <span class="n">Sequence</span><span class="p">[</span><span class="n">Sequence</span><span class="p">[</span><span class="nb">int</span><span class="p">]]</span>
                        <span class="p">)</span> <span class="o">-&gt;</span> <span class="n">ir</span><span class="o">.</span><span class="n">DenseIntElementsAttr</span><span class="p">:</span>
  <span class="c1"># Uneven replica groups are padded with -1.</span>
  <span class="n">groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="nb">list</span><span class="p">(</span><span class="n">itertools</span><span class="o">.</span><span class="n">zip_longest</span><span class="p">(</span><span class="o">*</span><span class="n">replica_groups</span><span class="p">,</span> <span class="n">fillvalue</span><span class="o">=-</span><span class="mi">1</span><span class="p">)),</span>
                    <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span><span class="o">.</span><span class="n">T</span>
  <span class="k">return</span> <span class="n">ir</span><span class="o">.</span><span class="n">DenseIntElementsAttr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">ascontiguousarray</span><span class="p">(</span><span class="n">groups</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_allreduce_impl</span><span class="p">(</span><span class="n">pos_reducer</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span>
  <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">pos_reducer</span><span class="p">(</span><span class="n">arg</span><span class="p">,</span> <span class="n">axes</span><span class="p">)</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>

<span class="k">def</span> <span class="nf">_allreduce_effectful_abstract_eval</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="c1"># TODO(frostig,mattjj,jekbradbury): maybe check aval names here</span>
  <span class="n">pos_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">))</span>
  <span class="n">named_shapes</span> <span class="o">=</span> <span class="p">[</span><span class="n">arg</span><span class="o">.</span><span class="n">named_shape</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
  <span class="n">named_axes</span> <span class="o">=</span> <span class="p">{</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)}</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="n">named_shapes</span> <span class="o">=</span> <span class="p">[{</span><span class="n">name</span><span class="p">:</span> <span class="n">size</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">arg</span><span class="o">.</span><span class="n">named_shape</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                     <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">named_axes</span><span class="p">}</span> <span class="k">for</span> <span class="n">arg</span> <span class="ow">in</span> <span class="n">args</span><span class="p">]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">pos_axes</span><span class="p">)</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;axis_index_groups can only be used with reductions over &quot;</span>
                       <span class="sa">f</span><span class="s2">&quot;named axes, but got: </span><span class="si">{</span><span class="n">axes</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="n">out_avals</span> <span class="o">=</span> <span class="p">[</span>
      <span class="n">ShapedArray</span><span class="p">(</span><span class="n">lax</span><span class="o">.</span><span class="n">_reduce_op_shape_rule</span><span class="p">(</span><span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">arg</span><span class="p">),</span> <span class="n">axes</span><span class="o">=</span><span class="n">pos_axes</span><span class="p">),</span>
                  <span class="n">arg</span><span class="o">.</span><span class="n">dtype</span><span class="p">,</span> <span class="n">named_shape</span><span class="o">=</span><span class="n">named_shape</span><span class="p">)</span>
      <span class="k">for</span> <span class="n">arg</span><span class="p">,</span> <span class="n">named_shape</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">args</span><span class="p">,</span> <span class="n">named_shapes</span><span class="p">)]</span>
  <span class="k">return</span> <span class="n">out_avals</span><span class="p">,</span> <span class="p">{</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">named_axes</span><span class="p">}</span>

<span class="k">def</span> <span class="nf">_allreduce_lowering</span><span class="p">(</span><span class="n">prim</span><span class="p">,</span> <span class="n">pos_fn</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="ow">and</span> <span class="p">(</span><span class="s2">&quot;tpu&quot;</span> <span class="ow">in</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">platforms</span><span class="p">):</span>
    <span class="n">len_0</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="o">!=</span> <span class="n">len_0</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">axis_index_groups</span><span class="p">):</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups must all be the same size for TPU lowering&quot;</span><span class="p">)</span>
  <span class="n">named_axes</span><span class="p">,</span> <span class="n">positional_axes</span> <span class="o">=</span> <span class="n">axes_partition</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="n">axes_partition</span><span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">positional_axes</span><span class="p">:</span>
    <span class="n">reducer</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">lower_fun</span><span class="p">(</span><span class="n">pos_fn</span><span class="p">,</span> <span class="n">multiple_results</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">_positional_reduce</span><span class="p">(</span><span class="n">aval</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
      <span class="n">aval_out</span> <span class="o">=</span> <span class="n">aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span>
          <span class="n">shape</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">delete</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">aval</span><span class="o">.</span><span class="n">shape</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">),</span>
                          <span class="n">positional_axes</span><span class="p">))</span>
      <span class="n">reducer_ctx</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">primitive</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">avals_in</span><span class="o">=</span><span class="p">[</span><span class="n">aval</span><span class="p">],</span> <span class="n">avals_out</span><span class="o">=</span><span class="p">[</span><span class="n">aval_out</span><span class="p">])</span>
      <span class="n">out</span><span class="p">,</span> <span class="o">=</span> <span class="n">reducer</span><span class="p">(</span><span class="n">reducer_ctx</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">positional_axes</span><span class="p">))[</span><span class="mi">0</span><span class="p">]</span>
      <span class="k">return</span> <span class="n">out</span>
    <span class="n">args</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">_positional_reduce</span><span class="p">,</span> <span class="n">ctx</span><span class="o">.</span><span class="n">avals_in</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">named_axes</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">args</span>

  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups_hlo</span><span class="p">(</span>
      <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">named_axes</span><span class="p">,</span>
                      <span class="n">axis_index_groups</span><span class="p">))</span>
  <span class="n">axis_context</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span>
  <span class="n">is_spmd</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">axis_context</span><span class="p">,</span>
      <span class="p">(</span><span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">ShardingContext</span><span class="p">),</span>
  <span class="p">)</span>

  <span class="k">def</span> <span class="nf">all_reduce</span><span class="p">(</span><span class="n">aval</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
    <span class="k">if</span> <span class="n">is_spmd</span><span class="p">:</span>
      <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
      <span class="n">other_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
          <span class="n">channel_handle</span><span class="o">=</span><span class="n">hlo</span><span class="o">.</span><span class="n">ChannelHandle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
              <span class="n">channel</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">DEVICE_TO_DEVICE_TYPE</span><span class="p">),</span>
          <span class="n">use_global_device_ids</span><span class="o">=</span><span class="n">ir</span><span class="o">.</span><span class="n">BoolAttr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">other_args</span> <span class="o">=</span> <span class="p">{}</span>
    <span class="n">op</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">AllReduceOp</span><span class="p">(</span>
        <span class="n">x</span><span class="o">.</span><span class="n">type</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">replica_groups</span><span class="o">=</span><span class="n">replica_groups</span><span class="p">,</span> <span class="o">**</span><span class="n">other_args</span><span class="p">)</span>
    <span class="n">scalar_aval</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">ShapedArray</span><span class="p">((),</span> <span class="n">aval</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>
    <span class="n">scalar_type</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">scalar_aval</span><span class="p">)</span>
    <span class="n">reducer_block</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">regions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scalar_type</span><span class="p">,</span> <span class="n">scalar_type</span><span class="p">)</span>
    <span class="k">with</span> <span class="n">ir</span><span class="o">.</span><span class="n">InsertionPoint</span><span class="p">(</span><span class="n">reducer_block</span><span class="p">):</span>
      <span class="n">lower_reducer</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">lower_fun</span><span class="p">(</span><span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">,</span> <span class="n">multiple_results</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
      <span class="n">reducer_ctx</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">primitive</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                                <span class="n">avals_in</span><span class="o">=</span><span class="p">[</span><span class="n">scalar_aval</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span> <span class="n">avals_out</span><span class="o">=</span><span class="p">[</span><span class="n">scalar_aval</span><span class="p">])</span>
      <span class="n">out_nodes</span> <span class="o">=</span> <span class="n">lower_reducer</span><span class="p">(</span>
          <span class="n">reducer_ctx</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="n">a</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">reducer_block</span><span class="o">.</span><span class="n">arguments</span><span class="p">))</span>
      <span class="n">hlo</span><span class="o">.</span><span class="n">return_</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">out_nodes</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">op</span><span class="o">.</span><span class="n">result</span>

  <span class="k">return</span> <span class="p">[</span><span class="n">all_reduce</span><span class="p">(</span><span class="n">aval</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">aval</span><span class="p">,</span> <span class="n">x</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">avals_in</span><span class="p">,</span> <span class="n">args</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">_psum_transpose_rule</span><span class="p">(</span><span class="n">cts</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="n">named_axes</span><span class="p">,</span> <span class="n">pos_axes</span> <span class="o">=</span> <span class="n">axes_partition</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
    <span class="n">axes_partition</span><span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>

  <span class="k">if</span> <span class="n">pos_axes</span><span class="p">:</span>
    <span class="k">def</span> <span class="nf">broadcast_positional</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">arg</span><span class="p">):</span>
      <span class="k">assert</span> <span class="n">ad</span><span class="o">.</span><span class="n">is_undefined_primal</span><span class="p">(</span><span class="n">arg</span><span class="p">)</span>
      <span class="k">if</span> <span class="nb">type</span><span class="p">(</span><span class="n">ct</span><span class="p">)</span> <span class="ow">is</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">:</span> <span class="k">return</span> <span class="n">ad</span><span class="o">.</span><span class="n">Zero</span><span class="p">(</span><span class="n">arg</span><span class="o">.</span><span class="n">aval</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_sum_transpose_rule</span><span class="p">(</span><span class="n">ct</span><span class="p">,</span> <span class="n">arg</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">pos_axes</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">cts</span> <span class="o">=</span> <span class="nb">map</span><span class="p">(</span><span class="n">broadcast_positional</span><span class="p">,</span> <span class="n">cts</span><span class="p">,</span> <span class="n">args</span><span class="p">)</span>

  <span class="c1"># We treat psum as psum + pbroadcast, which is why the transpose reduces</span>
  <span class="c1"># over the named axes again (unlike for positional axes).</span>
  <span class="n">nonzero_out_cts</span><span class="p">,</span> <span class="n">treedef</span> <span class="o">=</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_flatten</span><span class="p">(</span><span class="n">cts</span><span class="p">)</span>
  <span class="n">nonzero_in_cts</span> <span class="o">=</span> <span class="n">psum_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">nonzero_out_cts</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">named_axes</span><span class="p">),</span>
                               <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_unflatten</span><span class="p">(</span><span class="n">treedef</span><span class="p">,</span> <span class="n">nonzero_in_cts</span><span class="p">)</span>

<span class="n">psum_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;psum&#39;</span><span class="p">)</span>
<span class="n">psum_p</span><span class="o">.</span><span class="n">multiple_results</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">psum_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_impl</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_sum</span><span class="p">))</span>
<span class="n">psum_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_allreduce_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span>
    <span class="n">psum_p</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_lowering</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">add_p</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_sum</span><span class="p">))</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">psum_p</span><span class="p">,</span> <span class="n">_psum_transpose_rule</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">psum_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_reduction_batcher</span><span class="p">,</span> <span class="n">psum_p</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">psum_p</span><span class="p">]</span> <span class="o">=</span> \
  <span class="n">partial</span><span class="p">(</span><span class="n">_batched_reduction_collective</span><span class="p">,</span> <span class="n">psum_p</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">:</span> <span class="n">axis_size</span> <span class="o">*</span> <span class="n">v</span><span class="p">)</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">psum_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axes&#39;</span><span class="p">)</span>


<span class="c1"># We set a special bind rule for psum so that psum(1, &#39;i&#39;) can be evaluated at</span>
<span class="c1"># tracing time.</span>
<span class="nd">@psum_p</span><span class="o">.</span><span class="n">def_custom_bind</span>
<span class="k">def</span> <span class="nf">psum_bind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">core</span><span class="o">.</span><span class="n">Tracer</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">args</span><span class="p">):</span>
    <span class="n">named_axes</span><span class="p">,</span> <span class="n">pos_axes</span> <span class="o">=</span> <span class="n">axes_partition</span> <span class="o">=</span> <span class="p">[],</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">:</span>
      <span class="n">axes_partition</span><span class="p">[</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">axis</span><span class="p">)</span>
    <span class="k">def</span> <span class="nf">pos_reduce</span><span class="p">(</span><span class="n">x</span><span class="p">):</span>
      <span class="k">if</span> <span class="ow">not</span> <span class="n">pos_axes</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">x</span>
      <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_sum</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">[</span><span class="n">canonicalize_axis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">getattr</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="s1">&#39;ndim&#39;</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
                                 <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">pos_axes</span><span class="p">])</span>
    <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
      <span class="k">assert</span> <span class="ow">not</span> <span class="n">pos_axes</span>
      <span class="n">size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">size</span> <span class="o">=</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">([</span><span class="n">core</span><span class="o">.</span><span class="n">axis_frame</span><span class="p">(</span><span class="n">name</span><span class="p">)</span><span class="o">.</span><span class="n">size</span> <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="n">named_axes</span><span class="p">])</span>  <span class="c1"># type: ignore</span>
    <span class="k">return</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">lax</span><span class="o">.</span><span class="n">_const</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span> <span class="o">*</span> <span class="n">pos_reduce</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">args</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
      <span class="n">psum_p</span><span class="p">,</span> <span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>


<span class="n">pmax_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;pmax&#39;</span><span class="p">)</span>
<span class="n">pmax_p</span><span class="o">.</span><span class="n">multiple_results</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">pmax_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_impl</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_max</span><span class="p">))</span>
<span class="n">pmax_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_allreduce_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span>
    <span class="n">pmax_p</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_lowering</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">max_p</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_max</span><span class="p">))</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">pmax_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_reduction_batcher</span><span class="p">,</span> <span class="n">pmax_p</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">pmax_p</span><span class="p">]</span> <span class="o">=</span> \
  <span class="n">partial</span><span class="p">(</span><span class="n">_batched_reduction_collective</span><span class="p">,</span> <span class="n">pmax_p</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">:</span> <span class="n">v</span><span class="p">)</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">pmax_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axes&#39;</span><span class="p">)</span>


<span class="n">pmin_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;pmin&#39;</span><span class="p">)</span>
<span class="n">pmin_p</span><span class="o">.</span><span class="n">multiple_results</span> <span class="o">=</span> <span class="kc">True</span>
<span class="n">pmin_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_impl</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_min</span><span class="p">))</span>
<span class="n">pmin_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_allreduce_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span>
    <span class="n">pmin_p</span><span class="p">,</span> <span class="n">partial</span><span class="p">(</span><span class="n">_allreduce_lowering</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">min_p</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_reduce_min</span><span class="p">))</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">pmin_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_reduction_batcher</span><span class="p">,</span> <span class="n">pmin_p</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">pmin_p</span><span class="p">]</span> <span class="o">=</span> \
  <span class="n">partial</span><span class="p">(</span><span class="n">_batched_reduction_collective</span><span class="p">,</span> <span class="n">pmin_p</span><span class="p">,</span> <span class="k">lambda</span> <span class="n">v</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">:</span> <span class="n">v</span><span class="p">)</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">pmin_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axes&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_ppermute_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">perm</span><span class="p">):</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
  <span class="n">group_size</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="n">srcs</span><span class="p">,</span> <span class="n">dsts</span> <span class="o">=</span> <span class="n">unzip2</span><span class="p">((</span><span class="n">src</span> <span class="o">%</span> <span class="n">group_size</span><span class="p">,</span> <span class="n">dst</span> <span class="o">%</span> <span class="n">group_size</span><span class="p">)</span> <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="ow">in</span> <span class="n">perm</span><span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">srcs</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">srcs</span><span class="p">))</span> <span class="ow">and</span> <span class="nb">len</span><span class="p">(</span><span class="n">dsts</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">dsts</span><span class="p">))):</span>
    <span class="n">msg</span> <span class="o">=</span> <span class="s2">&quot;ppermute sources and destinations must be unique, got </span><span class="si">{}</span><span class="s2">.&quot;</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="n">msg</span><span class="o">.</span><span class="n">format</span><span class="p">(</span><span class="n">perm</span><span class="p">))</span>

  <span class="n">full_perm</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="nb">len</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">),</span> <span class="nb">len</span><span class="p">(</span><span class="n">perm</span><span class="p">),</span> <span class="mi">2</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">int64</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">grp</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">):</span>
    <span class="n">grp</span> <span class="o">=</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">grp</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">j</span><span class="p">,</span> <span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">)</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">perm</span><span class="p">):</span>
      <span class="n">full_perm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">grp</span><span class="p">[</span><span class="n">src</span><span class="p">]</span>
      <span class="n">full_perm</span><span class="p">[</span><span class="n">i</span><span class="p">,</span> <span class="n">j</span><span class="p">,</span> <span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="n">grp</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span>
  <span class="n">full_perm</span> <span class="o">=</span> <span class="n">full_perm</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

  <span class="n">axis_context</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span>
  <span class="n">is_manual</span> <span class="o">=</span> <span class="p">(</span>
      <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_context</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">)</span>
      <span class="ow">and</span> <span class="n">axis_context</span><span class="o">.</span><span class="n">manual_axes</span>
  <span class="p">)</span>
  <span class="k">if</span> <span class="n">is_manual</span><span class="p">:</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">channel_handle</span><span class="o">=</span><span class="n">hlo</span><span class="o">.</span><span class="n">ChannelHandle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">DEVICE_TO_DEVICE_TYPE</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="p">{}</span>

  <span class="k">return</span> <span class="n">hlo</span><span class="o">.</span><span class="n">CollectivePermuteOp</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">dense_int_elements</span><span class="p">(</span><span class="n">full_perm</span><span class="p">),</span> <span class="o">**</span><span class="n">other_args</span><span class="p">)</span><span class="o">.</span><span class="n">results</span>

<span class="k">def</span> <span class="nf">_ppermute_transpose_rule</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="n">srcs</span><span class="p">,</span> <span class="n">dsts</span> <span class="o">=</span> <span class="n">unzip2</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span>
  <span class="n">inverse_perm</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="nb">zip</span><span class="p">(</span><span class="n">dsts</span><span class="p">,</span> <span class="n">srcs</span><span class="p">))</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">ppermute</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">inverse_perm</span><span class="p">)]</span>

<span class="k">def</span> <span class="nf">_ppermute_batcher</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">perm</span><span class="p">):</span>
  <span class="p">(</span><span class="n">v</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">remaining_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axis_name</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">!=</span> <span class="n">frame_name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">remaining_axes</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">ppermute_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">perm</span><span class="o">=</span><span class="n">perm</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">remaining_axes</span><span class="p">),</span> <span class="n">d</span>
  <span class="k">if</span> <span class="n">remaining_axes</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;ppermute batcher only supports a single axis&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">frame_name</span><span class="p">,</span> <span class="s2">&quot;ppermute batcher called with a wrong axis!&quot;</span>
  <span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="n">perm</span><span class="p">)</span> <span class="o">==</span> <span class="n">axis_size</span><span class="p">,</span> <span class="s2">&quot;Permutation doesn&#39;t match the axis size!&quot;</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">d</span>
  <span class="n">perm_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="nb">int</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">src</span><span class="p">,</span> <span class="n">dst</span> <span class="ow">in</span> <span class="n">perm</span><span class="p">:</span>
    <span class="n">perm_indices</span><span class="p">[</span><span class="n">dst</span><span class="p">]</span> <span class="o">=</span> <span class="n">src</span>
  <span class="k">return</span> <span class="n">lax_numpy</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">perm_indices</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">d</span>

<span class="k">def</span> <span class="nf">_collective_batcher</span><span class="p">(</span><span class="n">prim</span><span class="p">,</span> <span class="n">args</span><span class="p">,</span> <span class="n">dims</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">):</span>
  <span class="k">return</span> <span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="o">*</span><span class="n">args</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">),</span> <span class="n">dims</span> <span class="k">if</span> <span class="n">prim</span><span class="o">.</span><span class="n">multiple_results</span> <span class="k">else</span> <span class="n">dims</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="n">ppermute_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;ppermute&#39;</span><span class="p">)</span>
<span class="n">ppermute_p</span><span class="o">.</span><span class="n">def_abstract_eval</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">ppermute_p</span><span class="p">,</span> <span class="n">_ppermute_transpose_rule</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">ppermute_p</span><span class="p">,</span> <span class="n">_ppermute_lowering</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">ppermute_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_collective_batcher</span><span class="p">,</span> <span class="n">ppermute_p</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">ppermute_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_ppermute_batcher</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">ppermute_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_pbroadcast_transpose_rule</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">source</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="n">is_source</span> <span class="o">=</span> <span class="n">axis_index</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span> <span class="o">==</span> <span class="n">source</span>
  <span class="n">tsum</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="n">t</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)</span>
  <span class="k">return</span> <span class="p">[</span><span class="n">lax_numpy</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">is_source</span><span class="p">,</span> <span class="n">tsum</span><span class="p">,</span> <span class="n">lax_numpy</span><span class="o">.</span><span class="n">zeros_like</span><span class="p">(</span><span class="n">t</span><span class="p">))]</span>

<span class="k">def</span> <span class="nf">_pbroadcast_batcher</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
  <span class="p">(</span><span class="n">v</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">remaining_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">axis</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axis_name</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">!=</span> <span class="n">frame_name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">remaining_axes</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;pbroadcast batcher only supports a single axis&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span> <span class="o">==</span> <span class="n">frame_name</span><span class="p">,</span> <span class="s2">&quot;pbroadcast batcher called with a wrong axis!&quot;</span>
  <span class="k">assert</span> <span class="n">source</span> <span class="o">&gt;=</span> <span class="mi">0</span> <span class="ow">and</span> <span class="n">source</span> <span class="o">&lt;</span> <span class="n">axis_size</span><span class="p">,</span> <span class="s2">&quot;collective broadcast doesn&#39;t fit in the axis size!&quot;</span>
  <span class="k">if</span> <span class="n">axis_size</span> <span class="o">==</span> <span class="mi">1</span> <span class="ow">and</span> <span class="n">remaining_axes</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">pbroadcast_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="n">source</span><span class="o">=</span><span class="n">source</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">remaining_axes</span><span class="p">),</span> <span class="n">d</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">v</span><span class="p">,</span> <span class="n">d</span>
  <span class="k">return</span> <span class="n">lax_numpy</span><span class="o">.</span><span class="n">take</span><span class="p">(</span><span class="n">v</span><span class="p">,</span> <span class="p">[</span><span class="n">source</span><span class="p">]</span> <span class="o">*</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">d</span><span class="p">),</span> <span class="n">d</span>

<span class="k">def</span> <span class="nf">_pbroadcast_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">source</span><span class="p">):</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="kc">None</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">source_to_front</span><span class="p">(</span><span class="n">group</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">group</span><span class="p">[</span><span class="n">source</span><span class="p">]]</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[:</span><span class="n">source</span><span class="p">])</span> <span class="o">+</span> <span class="nb">list</span><span class="p">(</span><span class="n">group</span><span class="p">[</span><span class="n">source</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:])</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="p">[</span><span class="n">source_to_front</span><span class="p">(</span><span class="n">group</span><span class="p">)</span> <span class="k">for</span> <span class="n">group</span> <span class="ow">in</span> <span class="n">replica_groups</span><span class="p">]</span>
  <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
  <span class="k">return</span> <span class="n">hlo</span><span class="o">.</span><span class="n">CollectiveBroadcastOp</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">replica_groups</span><span class="o">=</span><span class="n">_replica_groups_hlo</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">))</span><span class="o">.</span><span class="n">results</span>

<span class="n">pbroadcast_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;pbroadcast&#39;</span><span class="p">)</span>
<span class="n">pbroadcast_p</span><span class="o">.</span><span class="n">def_abstract_eval</span><span class="p">(</span><span class="k">lambda</span> <span class="n">x</span><span class="p">,</span> <span class="o">**</span><span class="n">params</span><span class="p">:</span> <span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">pbroadcast_p</span><span class="p">,</span> <span class="n">_pbroadcast_transpose_rule</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">pbroadcast_p</span><span class="p">,</span> <span class="n">_pbroadcast_lowering</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">pbroadcast_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_collective_batcher</span><span class="p">,</span> <span class="n">pbroadcast_p</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">pbroadcast_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_pbroadcast_batcher</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">pbroadcast_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_moveaxis</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dst</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="n">perm</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">)</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">src</span><span class="p">]</span>
  <span class="n">perm</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dst</span><span class="p">,</span> <span class="n">src</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">transpose</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">perm</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_splitaxis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">factor</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">new_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">%</span> <span class="n">factor</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">new_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">],</span> <span class="n">factor</span><span class="p">)</span>
  <span class="n">new_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">1</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">factor</span><span class="p">,</span> <span class="n">new_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">//</span> <span class="n">factor</span><span class="p">]</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_foldaxis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">new_shape</span><span class="p">[</span><span class="n">axis</span><span class="p">:</span><span class="n">axis</span><span class="o">+</span><span class="mi">2</span><span class="p">]</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span> <span class="o">*</span> <span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">axis</span> <span class="o">+</span> <span class="mi">1</span><span class="p">]]</span>
  <span class="k">return</span> <span class="n">x</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">new_shape</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_index_in_group</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">):</span>
  <span class="n">cur_device_id</span> <span class="o">=</span> <span class="n">axis_index</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">cur_device_id</span>
  <span class="c1"># We use argsort to invert the axis_index_groups permutation</span>
  <span class="n">flat_groups</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span><span class="o">.</span><span class="n">flatten</span><span class="p">()</span>
  <span class="n">device_id_to_idx</span> <span class="o">=</span> <span class="n">flat_groups</span><span class="o">.</span><span class="n">argsort</span><span class="p">()</span> <span class="o">%</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">squeeze</span><span class="p">(</span>
      <span class="n">slicing</span><span class="o">.</span><span class="n">dynamic_slice_in_dim</span><span class="p">(</span><span class="n">device_id_to_idx</span><span class="p">,</span> <span class="n">cur_device_id</span><span class="p">,</span> <span class="mi">1</span><span class="p">),</span> <span class="p">[</span><span class="mi">0</span><span class="p">])</span>


<span class="k">def</span> <span class="nf">_all_to_all_lowering</span><span class="p">(</span>
    <span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">tiled</span>
<span class="p">):</span>
  <span class="k">del</span> <span class="n">tiled</span>  <span class="c1"># expand_dims and squeeze is done in `all_to_all` if `True`</span>
  <span class="c1"># Workaround for AllToAll not being implemented on CPU.</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                                   <span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">==</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">x</span><span class="p">]</span>
  <span class="n">split_count</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">all</span><span class="p">(</span><span class="n">split_count</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">g</span><span class="p">)</span> <span class="k">for</span> <span class="n">g</span> <span class="ow">in</span> <span class="n">replica_groups</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s1">&#39;Replica groups must be equally sized&#39;</span><span class="p">)</span>
  <span class="n">is_spmd</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span><span class="p">,</span>
      <span class="p">(</span><span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">ShardingContext</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="k">if</span> <span class="n">is_spmd</span><span class="p">:</span>
    <span class="c1"># We want to emit the all-gather with global device IDs and a unique</span>
    <span class="c1"># channel ID, as otherwise it interprets the devices as replicas instead</span>
    <span class="c1"># of partitions - and XLA is configured with only a single replica.</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
    <span class="n">channel_handle</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">ChannelHandle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="n">channel</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">DEVICE_TO_DEVICE_TYPE</span><span class="p">)</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span><span class="n">channel_handle</span><span class="o">=</span><span class="n">channel_handle</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">return</span> <span class="n">hlo</span><span class="o">.</span><span class="n">AllToAllOp</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span>
      <span class="n">split_dimension</span><span class="o">=</span><span class="n">mlir</span><span class="o">.</span><span class="n">i64_attr</span><span class="p">(</span><span class="n">split_axis</span><span class="p">),</span>
      <span class="n">concat_dimension</span><span class="o">=</span><span class="n">mlir</span><span class="o">.</span><span class="n">i64_attr</span><span class="p">(</span><span class="n">concat_axis</span><span class="p">),</span>
      <span class="n">split_count</span><span class="o">=</span><span class="n">mlir</span><span class="o">.</span><span class="n">i64_attr</span><span class="p">(</span><span class="n">split_count</span><span class="p">),</span>
      <span class="n">replica_groups</span><span class="o">=</span><span class="n">_replica_groups_hlo</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">),</span>
      <span class="o">**</span><span class="n">other_args</span><span class="p">)</span><span class="o">.</span><span class="n">results</span>

<span class="k">def</span> <span class="nf">_all_to_all_transpose_rule</span><span class="p">(</span>
    <span class="n">cts</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">tiled</span>
<span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">all_to_all</span><span class="p">(</span>
      <span class="n">cts</span><span class="p">,</span>
      <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
      <span class="n">split_axis</span><span class="o">=</span><span class="n">concat_axis</span><span class="p">,</span>
      <span class="n">concat_axis</span><span class="o">=</span><span class="n">split_axis</span><span class="p">,</span>
      <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">),)</span>

<span class="k">def</span> <span class="nf">_all_to_all_batcher</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span>
                        <span class="n">tiled</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="n">d</span><span class="p">,</span> <span class="o">=</span> <span class="n">dims_in</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">all_to_all_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span>
      <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
      <span class="n">split_axis</span><span class="o">=</span><span class="n">split_axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&lt;=</span> <span class="n">split_axis</span><span class="p">),</span>
      <span class="n">concat_axis</span><span class="o">=</span><span class="n">concat_axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&lt;=</span> <span class="n">concat_axis</span><span class="p">),</span>
      <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">,</span>
  <span class="p">)</span>
  <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">d</span>

<span class="k">def</span> <span class="nf">_all_to_all_batched_collective</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span>
                                   <span class="n">axis_name</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span>
                                   <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="n">x</span><span class="p">,</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="n">d</span><span class="p">,</span> <span class="o">=</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="c1"># TODO(sharadmv,apaszke): Remove this broadcast that comes from</span>
    <span class="c1"># all_gather_transpose and instead avoid using all_to_all in</span>
    <span class="c1"># all_gather_transpose.</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">broadcast</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="o">*</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">))</span>
    <span class="n">d</span> <span class="o">=</span> <span class="mi">0</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">pos</span> <span class="o">=</span> <span class="n">axis_name</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">frame_name</span><span class="p">)</span>
    <span class="n">major_axes</span><span class="p">,</span> <span class="n">minor_axes</span> <span class="o">=</span> <span class="n">axis_name</span><span class="p">[:</span><span class="n">pos</span><span class="p">],</span> <span class="n">axis_name</span><span class="p">[</span><span class="n">pos</span> <span class="o">+</span> <span class="mi">1</span><span class="p">:]</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">major_axes</span><span class="p">,</span> <span class="n">minor_axes</span> <span class="o">=</span> <span class="p">(),</span> <span class="p">()</span>
  <span class="c1"># Optimized case when no splitting is necessary</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">major_axes</span> <span class="ow">and</span> <span class="ow">not</span> <span class="n">minor_axes</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">split_axis</span> <span class="o">==</span> <span class="n">concat_axis</span><span class="p">:</span>
      <span class="n">axis</span> <span class="o">=</span> <span class="n">split_axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&lt;=</span> <span class="n">split_axis</span><span class="p">)</span>
      <span class="n">d_pre_split</span> <span class="o">=</span> <span class="n">d</span>
      <span class="n">x</span> <span class="o">=</span> <span class="n">_splitaxis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
      <span class="n">d</span> <span class="o">+=</span> <span class="p">(</span><span class="n">axis</span> <span class="o">&lt;=</span> <span class="n">d</span><span class="p">)</span>
      <span class="k">return</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">moveaxis</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">axis</span><span class="p">),</span> <span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="n">d</span><span class="p">))),</span> <span class="n">d_pre_split</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">x_concat</span> <span class="o">=</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="n">concat_axis</span><span class="p">,</span> <span class="n">_moveaxis</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
      <span class="k">return</span> <span class="n">_splitaxis</span><span class="p">(</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">x_concat</span><span class="p">),</span> <span class="n">split_axis</span>
  <span class="c1"># Here we have to handle either the major or the minor dimensions</span>
  <span class="c1"># We will be accumulating chunks into the three leading dims: [Major, Current, Minor, ...]</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">d</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">_moveaxis</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)),</span> <span class="mi">1</span>
  <span class="n">split_axis</span> <span class="o">+=</span> <span class="mi">3</span><span class="p">;</span> <span class="n">concat_axis</span> <span class="o">+=</span> <span class="mi">3</span>  <span class="c1"># Offset by extra three leading dims</span>

  <span class="k">if</span> <span class="n">major_axes</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">all_to_all_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">major_axes</span><span class="p">,</span>
                          <span class="n">split_axis</span><span class="o">=</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span>
                          <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
                          <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
  <span class="c1"># Split out the local part into axis new_d (NOTE: d is already in axis 1)</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_splitaxis</span><span class="p">(</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="n">new_d</span> <span class="o">=</span> <span class="n">split_axis</span>
  <span class="n">concat_axis</span> <span class="o">+=</span> <span class="p">(</span><span class="n">split_axis</span> <span class="o">&lt;=</span> <span class="n">concat_axis</span><span class="p">)</span>  <span class="c1"># Offset the existing axes by the new batch axis</span>
  <span class="n">split_axis</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">if</span> <span class="n">minor_axes</span><span class="p">:</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">all_to_all_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">minor_axes</span><span class="p">,</span>
                          <span class="n">split_axis</span><span class="o">=</span><span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span>
                          <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
                          <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>

  <span class="c1"># Fold the chunk axes into a single one</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
  <span class="n">split_axis</span> <span class="o">-=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">concat_axis</span> <span class="o">-=</span> <span class="mi">2</span><span class="p">;</span> <span class="n">new_d</span> <span class="o">-=</span> <span class="mi">2</span>
  <span class="c1"># Fold gathered axes into concat_axis</span>
  <span class="n">x</span> <span class="o">=</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="n">concat_axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">_moveaxis</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">concat_axis</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">x</span><span class="p">))</span>
  <span class="n">new_d</span> <span class="o">-=</span> <span class="mi">1</span>  <span class="c1"># We&#39;ve removed 0th dimension, so new_d needs to be adjusted</span>
  <span class="k">return</span> <span class="n">x</span><span class="p">,</span> <span class="n">new_d</span>


<span class="k">def</span> <span class="nf">_all_to_all_effectful_abstract_eval</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">split_axis</span><span class="p">,</span> <span class="n">concat_axis</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">tiled</span>
<span class="p">):</span>
  <span class="k">del</span> <span class="n">tiled</span>  <span class="c1"># expand_dims and squeeze is done in `all_to_all` if `True`</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">input_aval</span> <span class="o">=</span> <span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">input_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">axis_size</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)</span> <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="kc">None</span> <span class="k">else</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span>
  <span class="k">assert</span> <span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]</span> <span class="o">%</span> <span class="n">axis_size</span> <span class="o">==</span> <span class="mi">0</span><span class="p">,</span> <span class="p">(</span><span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">],</span> <span class="n">axis_size</span><span class="p">)</span>
  <span class="n">shape</span><span class="p">[</span><span class="n">split_axis</span><span class="p">]</span> <span class="o">//=</span> <span class="n">axis_size</span>
  <span class="n">shape</span><span class="p">[</span><span class="n">concat_axis</span><span class="p">]</span> <span class="o">*=</span> <span class="n">axis_size</span>
  <span class="n">out_aval</span> <span class="o">=</span> <span class="n">input_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">),</span> <span class="n">weak_type</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
  <span class="n">effects</span> <span class="o">=</span> <span class="p">{</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">out_aval</span><span class="p">,</span> <span class="n">effects</span>


<span class="n">all_to_all_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;all_to_all&#39;</span><span class="p">)</span>
<span class="n">all_to_all_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_all_to_all_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">all_to_all_p</span><span class="p">,</span> <span class="n">_all_to_all_lowering</span><span class="p">)</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">all_to_all_p</span><span class="p">,</span> <span class="n">_all_to_all_transpose_rule</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">all_to_all_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_all_to_all_batcher</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">all_to_all_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_all_to_all_batched_collective</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">all_to_all_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="all_gather">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.all_gather.html#jax.lax.all_gather">[docs]</a>
<span class="k">def</span> <span class="nf">all_gather</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">tiled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;Gather values of x across all replicas.</span>

<span class="sd">  If ``x`` is a pytree then the result is equivalent to mapping this function to</span>
<span class="sd">  each leaf in the tree.</span>

<span class="sd">  This is equivalent to, but faster than, all_to_all(broadcast(x)).</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a pmapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    axis_index_groups: optional list of lists containing axis indices (e.g. for</span>
<span class="sd">      an axis of size 4, [[0, 1], [2, 3]] would run all gather over the first</span>
<span class="sd">      two and last two replicas). Groups must cover all axis indices exactly</span>
<span class="sd">      once, and all groups must be the same size.</span>
<span class="sd">    axis: a positional axis into which the chunks along ``axis_name`` will be</span>
<span class="sd">      concatenated.</span>
<span class="sd">    tiled: when ``False``, the chunks will be stacked into a fresh positional</span>
<span class="sd">      axis at index ``axis`` in the output. When ``True``, ``axis`` has to</span>
<span class="sd">      refer to an existing positional dimension and the chunks will be</span>
<span class="sd">      concatenated into that dimension.</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) representing the result of an all-gather along the axis</span>
<span class="sd">    ``axis_name``. Shapes are the same as ``x.shape``, but:</span>

<span class="sd">    - when ``tiled`` is ``False``, there is a new dimension equal to the</span>
<span class="sd">      size of axis ``axis_name`` in position ``axis``,</span>
<span class="sd">    - when ``tiled`` is ``True``, the size of dimension in position ``axis``</span>
<span class="sd">      is multiplied by the size of axis ``axis_name``.</span>

<span class="sd">  For example, with 4 XLA devices available:</span>

<span class="sd">  &gt;&gt;&gt; x = np.arange(4)</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.all_gather(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [[0 1 2 3]</span>
<span class="sd">   [0 1 2 3]</span>
<span class="sd">   [0 1 2 3]</span>
<span class="sd">   [0 1 2 3]]</span>

<span class="sd">  An example of using axis_index_groups, groups split by even &amp; odd device ids:</span>

<span class="sd">  &gt;&gt;&gt; x = np.arange(16).reshape(4, 4)</span>
<span class="sd">  &gt;&gt;&gt; print(x)</span>
<span class="sd">    [[ 0  1  2  3]</span>
<span class="sd">     [ 4  5  6  7]</span>
<span class="sd">     [ 8  9 10 11]</span>
<span class="sd">     [12 13 14 15]]</span>
<span class="sd">  &gt;&gt;&gt; def f(x):</span>
<span class="sd">  ...   return jax.lax.all_gather(</span>
<span class="sd">  ...       x, &#39;i&#39;, axis_index_groups=[[0, 2], [3, 1]])</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(f, axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [[[ 0  1  2  3]</span>
<span class="sd">    [ 8  9 10 11]]</span>
<span class="sd">   [[12 13 14 15]</span>
<span class="sd">    [ 4  5  6  7]]</span>
<span class="sd">   [[ 0  1  2  3]</span>
<span class="sd">    [ 8  9 10 11]]</span>
<span class="sd">   [[12 13 14 15]</span>
<span class="sd">    [ 4  5  6  7]]]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">axis_size</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">def</span> <span class="nf">bind</span><span class="p">(</span><span class="n">leaf</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">all_gather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
        <span class="n">leaf</span><span class="p">,</span>
        <span class="n">all_gather_dimension</span><span class="o">=</span><span class="n">canonicalize_axis</span><span class="p">(</span>
            <span class="n">axis</span><span class="p">,</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">leaf</span><span class="p">)</span> <span class="k">if</span> <span class="n">tiled</span> <span class="k">else</span> <span class="n">np</span><span class="o">.</span><span class="n">ndim</span><span class="p">(</span><span class="n">leaf</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">),</span>
        <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
        <span class="n">axis_size</span><span class="o">=</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>


<span class="k">def</span> <span class="nf">_expand</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">tiled</span><span class="p">,</span> <span class="n">x</span><span class="p">):</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="n">tile_size</span> <span class="o">=</span> <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span>
    <span class="n">shape</span><span class="p">[</span><span class="n">dim</span><span class="p">]</span> <span class="o">*=</span> <span class="n">size</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_const</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">slicing</span><span class="o">.</span><span class="n">dynamic_update_slice_in_dim</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">index</span> <span class="o">*</span> <span class="n">tile_size</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">dim</span><span class="p">,</span> <span class="n">size</span><span class="p">)</span>
    <span class="n">out</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">full</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">_const</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>
    <span class="k">return</span> <span class="n">slicing</span><span class="o">.</span><span class="n">dynamic_update_index_in_dim</span><span class="p">(</span><span class="n">out</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">index</span><span class="p">,</span> <span class="n">dim</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_all_gather_impl</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">raise</span> <span class="ne">AssertionError</span><span class="p">(</span><span class="s2">&quot;Unexpected call to _all_gather_impl&quot;</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_all_gather_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                         <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">,</span>
                         <span class="n">platform</span><span class="o">=</span><span class="kc">None</span><span class="p">):</span>
  <span class="n">x_aval</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">avals_in</span>
  <span class="n">out_aval</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">avals_out</span>
  <span class="n">axis_context</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span>
  <span class="n">is_spmd</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">axis_context</span><span class="p">,</span>
      <span class="p">(</span><span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">ShardingContext</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
    <span class="n">new_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">all_gather_dimension</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">broadcast_dimensions</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">new_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">all_gather_dimension</span><span class="p">]</span>
    <span class="n">x</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">broadcast_in_dim</span><span class="p">(</span>
        <span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">)),</span> <span class="n">x</span><span class="p">,</span>
        <span class="n">mlir</span><span class="o">.</span><span class="n">dense_int_array_v6</span><span class="p">(</span><span class="n">broadcast_dimensions</span><span class="p">))</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                                    <span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">is_spmd</span><span class="p">:</span>
    <span class="c1"># We want to emit the all-gather with global device IDs and a unique</span>
    <span class="c1"># channel ID, as otherwise it interprets the devices as replicas instead</span>
    <span class="c1"># of partitions - and XLA is configured with only a single replica.</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">channel_handle</span><span class="o">=</span><span class="n">hlo</span><span class="o">.</span><span class="n">ChannelHandle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">channel</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">DEVICE_TO_DEVICE_TYPE</span><span class="p">),</span>
        <span class="n">use_global_device_ids</span><span class="o">=</span><span class="n">ir</span><span class="o">.</span><span class="n">BoolAttr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="k">return</span> <span class="n">hlo</span><span class="o">.</span><span class="n">AllGatherOp</span><span class="p">(</span>
      <span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">out_aval</span><span class="p">),</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">all_gather_dim</span><span class="o">=</span><span class="n">mlir</span><span class="o">.</span><span class="n">i64_attr</span><span class="p">(</span><span class="n">all_gather_dimension</span><span class="p">),</span>
      <span class="n">replica_groups</span><span class="o">=</span><span class="n">_replica_groups_hlo</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">),</span>
      <span class="o">**</span><span class="n">other_args</span><span class="p">)</span><span class="o">.</span><span class="n">results</span>


<span class="k">def</span> <span class="nf">_all_gather_effectful_abstract_eval</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span>
<span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">x_aval</span> <span class="o">=</span> <span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="n">new_shape</span><span class="p">[</span><span class="n">all_gather_dimension</span><span class="p">]</span> <span class="o">*=</span> <span class="n">axis_size</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">new_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">)</span>
  <span class="n">new_named_shape</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">size</span> <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">named_shape</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                     <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">}</span>
  <span class="n">out_aval</span> <span class="o">=</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">named_shape</span><span class="o">=</span><span class="n">new_named_shape</span><span class="p">)</span>
  <span class="n">effects</span> <span class="o">=</span> <span class="p">{</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">out_aval</span><span class="p">,</span> <span class="n">effects</span>


<span class="k">def</span> <span class="nf">_all_gather_transpose_rule</span><span class="p">(</span><span class="n">cts</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">psum_scatter</span><span class="p">(</span><span class="n">cts</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
                       <span class="n">scatter_dimension</span><span class="o">=</span><span class="n">all_gather_dimension</span><span class="p">,</span>
                       <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
                       <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">),)</span>
  <span class="c1"># TODO(sharadmv,apaszke): re-enable this when we can properly detect replication.</span>
  <span class="c1"># return (lax.dynamic_index_in_dim(cts, idx, axis=all_gather_dimension, keepdims=False) * axis_size,)</span>

<span class="k">def</span> <span class="nf">_all_gather_batcher</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;=</span> <span class="n">all_gather_dimension</span><span class="p">:</span>
    <span class="n">all_gather_dimension</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">elif</span> <span class="ow">not</span> <span class="n">tiled</span><span class="p">:</span>  <span class="c1"># Tiled all-gather doesn&#39;t modify the set of dimensions</span>
    <span class="n">d</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">all_gather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span>
      <span class="n">all_gather_dimension</span><span class="o">=</span><span class="n">all_gather_dimension</span><span class="p">,</span>
      <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
      <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="n">axis_size</span><span class="o">=</span><span class="n">axis_size</span><span class="p">,</span>
      <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">d</span>

<span class="k">def</span> <span class="nf">_all_gather_batched_collective</span><span class="p">(</span><span class="n">frame_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span>
                                   <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                                   <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups not supported in vmap&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_size</span> <span class="o">==</span> <span class="n">frame_size</span><span class="p">,</span> <span class="s2">&quot;axis size doesn&#39;t match&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_name</span> <span class="o">==</span> <span class="p">(</span><span class="n">frame_name</span><span class="p">,),</span> <span class="s2">&quot;batcher called with wrong axis name&quot;</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="n">out_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">shape</span><span class="p">(</span><span class="n">x</span><span class="p">))</span>
    <span class="n">out_shape</span><span class="o">.</span><span class="n">insert</span><span class="p">(</span><span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">)</span>
    <span class="n">broadcast_dims</span> <span class="o">=</span> <span class="p">[</span><span class="n">i</span> <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">out_shape</span><span class="p">))</span> <span class="k">if</span> <span class="n">i</span> <span class="o">!=</span> <span class="n">all_gather_dimension</span><span class="p">]</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">broadcast_in_dim</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">out_shape</span><span class="p">,</span> <span class="n">broadcast_dims</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">_moveaxis</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">_foldaxis</span><span class="p">(</span><span class="n">all_gather_dimension</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span>

<span class="n">all_gather_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;all_gather&#39;</span><span class="p">)</span>
<span class="n">all_gather_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_all_gather_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">all_gather_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">_all_gather_impl</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">all_gather_p</span><span class="p">,</span> <span class="n">_all_gather_lowering</span><span class="p">)</span>
<span class="k">for</span> <span class="n">p</span> <span class="ow">in</span> <span class="p">(</span><span class="s2">&quot;cuda&quot;</span><span class="p">,</span> <span class="s2">&quot;rocm&quot;</span><span class="p">,</span> <span class="s2">&quot;tpu&quot;</span><span class="p">):</span>
  <span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">all_gather_p</span><span class="p">,</span>
                         <span class="n">partial</span><span class="p">(</span><span class="n">_all_gather_lowering</span><span class="p">,</span> <span class="n">platform</span><span class="o">=</span><span class="n">p</span><span class="p">),</span>
                         <span class="n">platform</span><span class="o">=</span><span class="n">p</span><span class="p">)</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">all_gather_p</span><span class="p">,</span> <span class="n">_all_gather_transpose_rule</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">all_gather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_all_gather_batcher</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">all_gather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_all_gather_batched_collective</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">all_gather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_reduce_scatter_lowering</span><span class="p">(</span>
    <span class="n">prim</span><span class="p">,</span> <span class="n">ctx</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span>
    <span class="o">*</span><span class="p">,</span> <span class="n">scatter_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
    <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="n">x_aval</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">avals_in</span>
  <span class="n">aval_out</span><span class="p">,</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">avals_out</span>
  <span class="n">scalar_aval</span> <span class="o">=</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="p">())</span>
  <span class="n">replica_groups</span> <span class="o">=</span> <span class="n">_replica_groups</span><span class="p">(</span><span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                                   <span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">scatter_out_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">scatter_out_shape</span><span class="p">[</span><span class="n">scatter_dimension</span><span class="p">]</span> <span class="o">//=</span> <span class="n">axis_size</span>
  <span class="n">axis_context</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span>
  <span class="n">is_spmd</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">axis_context</span><span class="p">,</span>
      <span class="p">(</span><span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">ShardingContext</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="k">if</span> <span class="n">is_spmd</span><span class="p">:</span>
    <span class="c1"># We want to emit the all-gather with global device IDs and a unique</span>
    <span class="c1"># channel ID, as otherwise it interprets the devices as replicas instead</span>
    <span class="c1"># of partitions - and XLA is configured with only a single replica.</span>
    <span class="n">channel</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">new_channel</span><span class="p">()</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="nb">dict</span><span class="p">(</span>
        <span class="n">channel_handle</span><span class="o">=</span><span class="n">hlo</span><span class="o">.</span><span class="n">ChannelHandle</span><span class="o">.</span><span class="n">get</span><span class="p">(</span>
            <span class="n">channel</span><span class="p">,</span> <span class="n">mlir</span><span class="o">.</span><span class="n">DEVICE_TO_DEVICE_TYPE</span><span class="p">),</span>
        <span class="n">use_global_device_ids</span><span class="o">=</span><span class="n">ir</span><span class="o">.</span><span class="n">BoolAttr</span><span class="o">.</span><span class="n">get</span><span class="p">(</span><span class="kc">True</span><span class="p">))</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">other_args</span> <span class="o">=</span> <span class="p">{}</span>
  <span class="n">op</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">ReduceScatterOp</span><span class="p">(</span>
      <span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">scatter_out_shape</span><span class="p">)),</span>
      <span class="n">x</span><span class="p">,</span>
      <span class="n">scatter_dimension</span><span class="o">=</span><span class="n">mlir</span><span class="o">.</span><span class="n">i64_attr</span><span class="p">(</span><span class="n">scatter_dimension</span><span class="p">),</span>
      <span class="n">replica_groups</span><span class="o">=</span><span class="n">_replica_groups_hlo</span><span class="p">(</span><span class="n">replica_groups</span><span class="p">),</span>
      <span class="o">**</span><span class="n">other_args</span><span class="p">)</span>
  <span class="n">scalar_type</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">scalar_aval</span><span class="p">)</span>
  <span class="n">reducer_block</span> <span class="o">=</span> <span class="n">op</span><span class="o">.</span><span class="n">regions</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">blocks</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">scalar_type</span><span class="p">,</span> <span class="n">scalar_type</span><span class="p">)</span>
  <span class="k">with</span> <span class="n">ir</span><span class="o">.</span><span class="n">InsertionPoint</span><span class="p">(</span><span class="n">reducer_block</span><span class="p">):</span>
    <span class="n">lower_reducer</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">lower_fun</span><span class="p">(</span><span class="n">prim</span><span class="o">.</span><span class="n">bind</span><span class="p">,</span> <span class="n">multiple_results</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
    <span class="n">reducer_ctx</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">replace</span><span class="p">(</span><span class="n">primitive</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                              <span class="n">avals_in</span><span class="o">=</span><span class="p">[</span><span class="n">scalar_aval</span><span class="p">]</span> <span class="o">*</span> <span class="mi">2</span><span class="p">,</span>
                              <span class="n">avals_out</span><span class="o">=</span><span class="p">[</span><span class="n">scalar_aval</span><span class="p">])</span>
    <span class="n">out_nodes</span> <span class="o">=</span> <span class="n">lower_reducer</span><span class="p">(</span>
        <span class="n">reducer_ctx</span><span class="p">,</span> <span class="o">*</span><span class="p">([</span><span class="n">a</span><span class="p">]</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">reducer_block</span><span class="o">.</span><span class="n">arguments</span><span class="p">))</span>
    <span class="n">hlo</span><span class="o">.</span><span class="n">return_</span><span class="p">(</span><span class="n">util</span><span class="o">.</span><span class="n">flatten</span><span class="p">(</span><span class="n">out_nodes</span><span class="p">))</span>

  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">op</span><span class="o">.</span><span class="n">results</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="p">[</span><span class="n">hlo</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">mlir</span><span class="o">.</span><span class="n">aval_to_ir_type</span><span class="p">(</span><span class="n">aval_out</span><span class="p">),</span> <span class="n">op</span><span class="o">.</span><span class="n">result</span><span class="p">)]</span>


<span class="k">def</span> <span class="nf">_reduce_scatter_effectful_abstract_eval</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">scatter_dimension</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span>
<span class="p">):</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">list</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">)):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="n">x_aval</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">raise_to_shaped</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>
  <span class="n">new_shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">x_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="n">scatter_dim_input_size</span> <span class="o">=</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="n">scatter_dimension</span><span class="p">]</span>
  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">scatter_dim_input_size</span> <span class="o">%</span> <span class="n">axis_size</span> <span class="o">!=</span> <span class="mi">0</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;tiled reduce_scatter operand scatter dimension size &quot;</span>
                       <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scatter_dim_input_size</span><span class="si">}</span><span class="s2"> must be divisible by &quot;</span>
                       <span class="sa">f</span><span class="s2">&quot;shard_count </span><span class="si">{</span><span class="n">axis_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="n">new_shape</span><span class="p">[</span><span class="n">scatter_dimension</span><span class="p">]</span> <span class="o">=</span> <span class="n">scatter_dim_input_size</span> <span class="o">//</span> <span class="n">axis_size</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">if</span> <span class="n">scatter_dim_input_size</span> <span class="o">!=</span> <span class="n">axis_size</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;reduce_scatter operand scatter dimension size &quot;</span>
                       <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">scatter_dim_input_size</span><span class="si">}</span><span class="s2"> must match shard count &quot;</span>
                       <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">axis_size</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
    <span class="k">del</span> <span class="n">new_shape</span><span class="p">[</span><span class="n">scatter_dimension</span><span class="p">]</span>

  <span class="n">new_named_shape</span> <span class="o">=</span> <span class="p">{</span>
      <span class="n">name</span><span class="p">:</span> <span class="n">size</span>
      <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">named_shape</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
      <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis_name</span>
  <span class="p">}</span>
  <span class="n">out_aval</span> <span class="o">=</span> <span class="n">x_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">shape</span><span class="o">=</span><span class="n">new_shape</span><span class="p">,</span> <span class="n">named_shape</span><span class="o">=</span><span class="n">new_named_shape</span><span class="p">)</span>
  <span class="n">effects</span> <span class="o">=</span> <span class="p">{</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">out_aval</span><span class="p">,</span> <span class="n">effects</span>


<span class="k">def</span> <span class="nf">_reduce_scatter_transpose_rule</span><span class="p">(</span><span class="n">cts</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">scatter_dimension</span><span class="p">,</span>
                                   <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">(</span><span class="n">all_gather</span><span class="p">(</span><span class="n">cts</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
                     <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
                     <span class="n">axis</span><span class="o">=</span><span class="n">scatter_dimension</span><span class="p">,</span> <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">),)</span>


<span class="k">def</span> <span class="nf">_reduce_scatter_batcher</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">scatter_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                            <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">d</span> <span class="o">&lt;=</span> <span class="n">scatter_dimension</span><span class="p">:</span>
    <span class="n">scatter_dimension</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="k">elif</span> <span class="ow">not</span> <span class="n">tiled</span><span class="p">:</span>  <span class="c1"># Tiled all-scatter doesn&#39;t change the rank</span>
    <span class="n">d</span> <span class="o">+=</span> <span class="mi">1</span>
  <span class="n">result</span> <span class="o">=</span> <span class="n">reduce_scatter_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span>
      <span class="n">scatter_dimension</span><span class="o">=</span><span class="n">scatter_dimension</span><span class="p">,</span>
      <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
      <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="n">axis_size</span><span class="o">=</span><span class="n">axis_size</span><span class="p">,</span>
      <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">d</span>

<span class="k">def</span> <span class="nf">_reduce_scatter_collective</span><span class="p">(</span><span class="n">frame_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span>
                               <span class="n">scatter_dimension</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                               <span class="n">axis_index_groups</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">tiled</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_index_groups</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;axis_index_groups not supported in vmap&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_size</span> <span class="o">==</span> <span class="n">frame_size</span><span class="p">,</span> <span class="s2">&quot;axis size doesn&#39;t match&quot;</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
    <span class="n">axis_name</span> <span class="o">=</span> <span class="p">(</span><span class="n">axis_name</span><span class="p">,)</span>
  <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="k">assert</span> <span class="n">axis_name</span> <span class="o">==</span> <span class="p">(</span><span class="n">frame_name</span><span class="p">,),</span> <span class="s2">&quot;batcher called with wrong axis name&quot;</span>
  <span class="p">(</span><span class="n">x</span><span class="p">,),</span> <span class="p">(</span><span class="n">d</span><span class="p">,)</span> <span class="o">=</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">d</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">dy</span> <span class="o">=</span> <span class="n">x</span> <span class="o">*</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">scatter_dimension</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">y</span><span class="p">,</span> <span class="n">dy</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">reduce</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">add</span><span class="p">,</span> <span class="p">(</span><span class="n">d</span><span class="p">,)),</span> <span class="n">scatter_dimension</span>
  <span class="k">if</span> <span class="n">tiled</span><span class="p">:</span>
    <span class="n">y</span> <span class="o">=</span> <span class="n">_splitaxis</span><span class="p">(</span><span class="n">dy</span><span class="p">,</span> <span class="n">axis_size</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">y</span><span class="p">,</span> <span class="n">dy</span>


<span class="n">reduce_scatter_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s2">&quot;reduce_scatter&quot;</span><span class="p">)</span>
<span class="n">reduce_scatter_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span>
    <span class="n">_reduce_scatter_effectful_abstract_eval</span>
<span class="p">)</span>
<span class="n">ad</span><span class="o">.</span><span class="n">deflinear2</span><span class="p">(</span><span class="n">reduce_scatter_p</span><span class="p">,</span> <span class="n">_reduce_scatter_transpose_rule</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">reduce_scatter_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_reduce_scatter_batcher</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">reduce_scatter_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_reduce_scatter_collective</span>

<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">reduce_scatter_p</span><span class="p">,</span>
                       <span class="n">partial</span><span class="p">(</span><span class="n">_reduce_scatter_lowering</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">add_p</span><span class="p">))</span>

<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">reduce_scatter_p</span><span class="p">]</span> <span class="o">=</span> \
    <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>


<div class="viewcode-block" id="psum_scatter">
<a class="viewcode-back" href="../../../../_autosummary/jax.lax.psum_scatter.html#jax.lax.psum_scatter">[docs]</a>
<span class="k">def</span> <span class="nf">psum_scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">scatter_dimension</span><span class="o">=</span><span class="mi">0</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
                 <span class="n">tiled</span><span class="o">=</span><span class="kc">False</span><span class="p">):</span>
<span class="w">  </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">  Like ``psum(x, axis_name)`` but each device retains only part of the result.</span>

<span class="sd">  For example, ``psum_scatter(x, axis_name, scatter_dimension=0, tiled=False)``</span>
<span class="sd">  computes the same value as ``psum(x, axis_name)[axis_index(axis_name)]``, but</span>
<span class="sd">  it is more efficient. Thus the ``psum`` result is left scattered along the</span>
<span class="sd">  mapped axis.</span>

<span class="sd">  One efficient algorithm for computing ``psum(x, axis_name)`` is to perform a</span>
<span class="sd">  ``psum_scatter`` followed by an ``all_gather``, essentially evaluating</span>
<span class="sd">  ``all_gather(psum_scatter(x, axis_name))``. So we can think of</span>
<span class="sd">  ``psum_scatter`` as &quot;the first half&quot; of a ``psum``.</span>

<span class="sd">  Args:</span>
<span class="sd">    x: array(s) with a mapped axis named ``axis_name``.</span>
<span class="sd">    axis_name: hashable Python object used to name a mapped axis (see the</span>
<span class="sd">      :func:`jax.pmap` documentation for more details).</span>
<span class="sd">    scatter_dimension: a positional axis into which the all-reduce result along</span>
<span class="sd">      ``axis_name`` will be scattered.</span>
<span class="sd">    axis_index_groups: optional list of lists of integers containing axis</span>
<span class="sd">      indices. For example, for an axis of size 4,</span>
<span class="sd">      ``axis_index_groups=[[0, 1], [2, 3]]`` would run reduce-scatter over the</span>
<span class="sd">      first two and the last two axis indices. Groups must cover all axis</span>
<span class="sd">      indices exactly once, and all groups must be the same size.</span>
<span class="sd">    tiled: boolean representing whether to use rank-preserving &#39;tiled&#39; behavior.</span>
<span class="sd">      When ``False`` (the default value), the size of dimension in</span>
<span class="sd">      ``scatter_dimension`` must match the size of axis ``axis_name`` (or the</span>
<span class="sd">      group size if ``axis_index_groups`` is given). After scattering the</span>
<span class="sd">      all-reduce result along ``scatter_dimension``, the output is sequeezed by</span>
<span class="sd">      removing ``scatter_dimension``, so the result has lower rank than the</span>
<span class="sd">      input. When ``True``, the size of dimension in ``scatter_dimension`` must</span>
<span class="sd">      be dividible by the size of axis ``axis_name`` (or the group size if</span>
<span class="sd">      ``axis_index_groups`` is given), and the ``scatter_dimension`` axis is</span>
<span class="sd">      preserved (so the result has the same rank as the input).</span>

<span class="sd">  Returns:</span>
<span class="sd">    Array(s) with the similar shape as ``x``, except the size of dimension in</span>
<span class="sd">    position ``scatter_dimension`` is divided by the size of axis ``axis_name``</span>
<span class="sd">    (when ``tiled=True``), or the dimension in position ``scatter_dimension`` is</span>
<span class="sd">    eliminated (when ``tiled=False``).</span>

<span class="sd">  For example, with 4 XLA devices available:</span>

<span class="sd">  &gt;&gt;&gt; x = np.arange(16).reshape(4, 4)</span>
<span class="sd">  &gt;&gt;&gt; print(x)</span>
<span class="sd">  [[ 0  1  2  3]</span>
<span class="sd">   [ 4  5  6  7]</span>
<span class="sd">   [ 8  9 10 11]</span>
<span class="sd">   [12 13 14 15]]</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum_scatter(x, &#39;i&#39;), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [24 28 32 36]</span>

<span class="sd">  if using tiled:</span>

<span class="sd">  &gt;&gt;&gt; y = jax.pmap(lambda x: jax.lax.psum_scatter(x, &#39;i&#39;, tiled=True), axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [[24]</span>
<span class="sd">   [28]</span>
<span class="sd">   [32]</span>
<span class="sd">   [36]]</span>

<span class="sd">  An example of using axis_index_groups:</span>

<span class="sd">  &gt;&gt;&gt; def f(x):</span>
<span class="sd">  ...   return jax.lax.psum_scatter(</span>
<span class="sd">  ...       x, &#39;i&#39;, axis_index_groups=[[0, 2], [3, 1]], tiled=True)</span>
<span class="sd">  &gt;&gt;&gt; y = jax.pmap(f, axis_name=&#39;i&#39;)(x)</span>
<span class="sd">  &gt;&gt;&gt; print(y)</span>
<span class="sd">  [[ 8 10]</span>
<span class="sd">   [20 22]</span>
<span class="sd">   [12 14]</span>
<span class="sd">   [16 18]]</span>
<span class="sd">  &quot;&quot;&quot;</span>
  <span class="n">axis_size</span> <span class="o">=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">axis_index_groups</span> <span class="o">=</span> <span class="n">_canonicalize_axis_index_groups</span><span class="p">(</span><span class="n">axis_index_groups</span><span class="p">)</span>
  <span class="n">bind</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span>
      <span class="n">reduce_scatter_p</span><span class="o">.</span><span class="n">bind</span><span class="p">,</span>
      <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span>
      <span class="n">scatter_dimension</span><span class="o">=</span><span class="n">scatter_dimension</span><span class="p">,</span>
      <span class="n">axis_index_groups</span><span class="o">=</span><span class="n">axis_index_groups</span><span class="p">,</span>
      <span class="n">axis_size</span><span class="o">=</span><span class="n">axis_size</span><span class="p">,</span>
      <span class="n">tiled</span><span class="o">=</span><span class="n">tiled</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">tree_util</span><span class="o">.</span><span class="n">tree_map</span><span class="p">(</span><span class="n">bind</span><span class="p">,</span> <span class="n">x</span><span class="p">)</span></div>



<span class="k">def</span> <span class="nf">_build_axis_index_lowering_hlo</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">axis_env</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="nb">tuple</span><span class="p">):</span>
    <span class="k">assert</span> <span class="n">axis_name</span><span class="p">,</span> <span class="s1">&#39;empty axis name&#39;</span>
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">1</span><span class="p">:</span>
      <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span>
          <span class="s1">&#39;`axis_index` translation rule does not support multiple axis names.&#39;</span><span class="p">)</span>
    <span class="n">axis_name</span><span class="p">,</span> <span class="o">=</span> <span class="n">axis_name</span>
  <span class="n">axis_pos</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">axis_env</span><span class="o">.</span><span class="n">names</span><span class="p">)</span><span class="o">.</span><span class="n">index</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
  <span class="n">nreplicas</span> <span class="o">=</span> <span class="n">axis_env</span><span class="o">.</span><span class="n">nreps</span> <span class="o">//</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis_env</span><span class="o">.</span><span class="n">sizes</span><span class="p">)</span>
  <span class="n">div</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">ir_constant</span><span class="p">(</span>
      <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span>
          <span class="n">nreplicas</span> <span class="o">*</span> <span class="n">math</span><span class="o">.</span><span class="n">prod</span><span class="p">(</span><span class="n">axis_env</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="n">axis_pos</span> <span class="o">+</span> <span class="mi">1</span> <span class="p">:]),</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span>
      <span class="p">)</span>
  <span class="p">)</span>
  <span class="n">mod</span> <span class="o">=</span> <span class="n">mlir</span><span class="o">.</span><span class="n">ir_constant</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">axis_env</span><span class="o">.</span><span class="n">sizes</span><span class="p">[</span><span class="n">axis_pos</span><span class="p">],</span> <span class="n">dtype</span><span class="o">=</span><span class="n">np</span><span class="o">.</span><span class="n">uint32</span><span class="p">))</span>
  <span class="n">axis_context</span> <span class="o">=</span> <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_context</span>
  <span class="n">is_spmd</span> <span class="o">=</span> <span class="nb">isinstance</span><span class="p">(</span>
      <span class="n">axis_context</span><span class="p">,</span>
      <span class="p">(</span><span class="n">sharding_impls</span><span class="o">.</span><span class="n">SPMDAxisContext</span><span class="p">,</span> <span class="n">sharding_impls</span><span class="o">.</span><span class="n">ShardingContext</span><span class="p">),</span>
  <span class="p">)</span>
  <span class="k">if</span> <span class="n">is_spmd</span><span class="p">:</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">partition_id</span><span class="p">()</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">device_id</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">replica_id</span><span class="p">()</span>
  <span class="n">unsigned_index</span> <span class="o">=</span> <span class="n">hlo</span><span class="o">.</span><span class="n">remainder</span><span class="p">(</span><span class="n">hlo</span><span class="o">.</span><span class="n">divide</span><span class="p">(</span><span class="n">device_id</span><span class="p">,</span> <span class="n">div</span><span class="p">),</span> <span class="n">mod</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">hlo</span><span class="o">.</span><span class="n">convert</span><span class="p">(</span>
      <span class="n">ir</span><span class="o">.</span><span class="n">RankedTensorType</span><span class="o">.</span><span class="n">get</span><span class="p">([],</span> <span class="n">ir</span><span class="o">.</span><span class="n">IntegerType</span><span class="o">.</span><span class="n">get_signless</span><span class="p">(</span><span class="mi">32</span><span class="p">)),</span>
      <span class="n">unsigned_index</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_axis_index_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="k">return</span> <span class="p">[</span>
      <span class="n">_build_axis_index_lowering_hlo</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                                     <span class="n">ctx</span><span class="o">.</span><span class="n">module_context</span><span class="o">.</span><span class="n">axis_env</span><span class="p">)</span>
  <span class="p">]</span>


<span class="k">def</span> <span class="nf">_axis_index_effectful_abstract_eval</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="n">frame</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">axis_frame</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
  <span class="n">out_aval</span> <span class="o">=</span> <span class="n">ShapedArray</span><span class="p">((),</span> <span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">named_shape</span><span class="o">=</span><span class="p">{</span><span class="n">axis_name</span><span class="p">:</span> <span class="n">frame</span><span class="o">.</span><span class="n">size</span><span class="p">})</span>
  <span class="k">return</span> <span class="n">out_aval</span><span class="p">,</span> <span class="p">{</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)}</span>


<span class="n">axis_index_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">Primitive</span><span class="p">(</span><span class="s1">&#39;axis_index&#39;</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">axis_index_p</span><span class="p">,</span> <span class="n">_axis_index_lowering</span><span class="p">)</span>
<span class="n">axis_index_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span><span class="p">(</span><span class="n">_axis_index_effectful_abstract_eval</span><span class="p">)</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">axis_index_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>

<span class="c1"># Axis index doesn&#39;t get any arguments, so that the default bind would have no</span>
<span class="c1"># way to call into a data-dependency based trace such as vmap. Each trace that</span>
<span class="c1"># wants to bind an axis name has to additionally implement `process_axis_index`</span>
<span class="c1"># and put its main trace on the axis env stack.</span>
<span class="k">def</span> <span class="nf">_axis_index_bind</span><span class="p">(</span><span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">):</span>
  <span class="k">def</span> <span class="nf">name_idx</span><span class="p">(</span><span class="n">name</span><span class="p">):</span>
    <span class="n">frame</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">axis_frame</span><span class="p">(</span><span class="n">name</span><span class="p">)</span>
    <span class="n">dynamic</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">thread_local_state</span><span class="o">.</span><span class="n">trace_state</span><span class="o">.</span><span class="n">trace_stack</span><span class="o">.</span><span class="n">dynamic</span>
    <span class="k">if</span> <span class="p">(</span><span class="n">frame</span><span class="o">.</span><span class="n">main_trace</span> <span class="ow">is</span> <span class="kc">None</span> <span class="ow">or</span> <span class="n">dynamic</span><span class="o">.</span><span class="n">level</span> <span class="o">&gt;</span> <span class="n">frame</span><span class="o">.</span><span class="n">main_trace</span><span class="o">.</span><span class="n">level</span><span class="p">):</span>
      <span class="k">return</span> <span class="n">core</span><span class="o">.</span><span class="n">Primitive</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">axis_index_p</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">name</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
      <span class="n">trace</span> <span class="o">=</span> <span class="n">frame</span><span class="o">.</span><span class="n">main_trace</span><span class="o">.</span><span class="n">with_cur_sublevel</span><span class="p">()</span>
      <span class="k">return</span> <span class="n">trace</span><span class="o">.</span><span class="n">process_axis_index</span><span class="p">(</span><span class="n">frame</span><span class="p">)</span>

  <span class="k">if</span> <span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis_name</span><span class="p">,</span> <span class="p">(</span><span class="nb">tuple</span><span class="p">,</span> <span class="nb">list</span><span class="p">)):</span>
    <span class="k">return</span> <span class="n">name_idx</span><span class="p">(</span><span class="n">axis_name</span><span class="p">)</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="n">inner_size</span> <span class="o">=</span> <span class="mi">1</span>
    <span class="n">index</span> <span class="o">=</span> <span class="mi">0</span>
    <span class="k">for</span> <span class="n">name</span> <span class="ow">in</span> <span class="nb">reversed</span><span class="p">(</span><span class="n">axis_name</span><span class="p">):</span>
      <span class="n">index</span> <span class="o">+=</span> <span class="n">name_idx</span><span class="p">(</span><span class="n">name</span><span class="p">)</span> <span class="o">*</span> <span class="n">inner_size</span>
      <span class="n">inner_size</span> <span class="o">*=</span> <span class="n">psum</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">name</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">index</span>
<span class="n">axis_index_p</span><span class="o">.</span><span class="n">def_custom_bind</span><span class="p">(</span><span class="n">_axis_index_bind</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_vmap_process_axis_index</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">frame</span><span class="p">):</span>
  <span class="k">assert</span> <span class="n">frame</span><span class="o">.</span><span class="n">size</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span>
  <span class="k">return</span> <span class="n">batching</span><span class="o">.</span><span class="n">BatchTracer</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">lax</span><span class="o">.</span><span class="n">iota</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">int32</span><span class="p">,</span> <span class="n">frame</span><span class="o">.</span><span class="n">size</span><span class="p">),</span> <span class="mi">0</span><span class="p">)</span>
<span class="n">batching</span><span class="o">.</span><span class="n">BatchTrace</span><span class="o">.</span><span class="n">process_axis_index</span> <span class="o">=</span> <span class="n">_vmap_process_axis_index</span>  <span class="c1"># type: ignore</span>


<span class="n">pdot_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;pdot&#39;</span><span class="p">)</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">pdot_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axis_name&#39;</span><span class="p">)</span>

<span class="nd">@pdot_p</span><span class="o">.</span><span class="n">def_impl</span>
<span class="k">def</span> <span class="nf">_pdot_impl</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="k">if</span> <span class="n">axis_name</span><span class="p">:</span> <span class="k">raise</span> <span class="ne">NameError</span><span class="p">(</span><span class="sa">f</span><span class="s2">&quot;unbound axis name: </span><span class="si">{</span><span class="n">axis_name</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="si">}</span><span class="s2">&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">dot_general</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="p">(</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">),</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>


<span class="nd">@pdot_p</span><span class="o">.</span><span class="n">def_effectful_abstract_eval</span>
<span class="k">def</span> <span class="nf">_pdot_effectful_abstract_eval</span><span class="p">(</span>
    <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span>
<span class="p">):</span>
  <span class="c1"># TODO(frostig,mattjj,jekbradbury): check inputs have given axis names?</span>
  <span class="k">if</span> <span class="ow">not</span> <span class="nb">len</span><span class="p">(</span><span class="nb">set</span><span class="p">(</span><span class="n">axis_name</span><span class="p">))</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="n">axis_name</span><span class="p">):</span> <span class="k">raise</span> <span class="ne">ValueError</span>
  <span class="n">pos_aval</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">dot_general_p</span><span class="o">.</span><span class="n">abstract_eval</span><span class="p">(</span>
      <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="o">=</span><span class="p">[</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">],</span>
      <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">preferred_element_type</span><span class="o">=</span><span class="kc">None</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
  <span class="n">common_named_shape</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">join_named_shapes</span><span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">named_shape</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">named_shape</span><span class="p">)</span>
  <span class="n">named_shape</span> <span class="o">=</span> <span class="p">{</span><span class="n">name</span><span class="p">:</span> <span class="n">size</span>
                 <span class="k">for</span> <span class="n">name</span><span class="p">,</span> <span class="n">size</span> <span class="ow">in</span> <span class="n">common_named_shape</span><span class="o">.</span><span class="n">items</span><span class="p">()</span>
                 <span class="k">if</span> <span class="n">name</span> <span class="ow">not</span> <span class="ow">in</span> <span class="n">axis_name</span><span class="p">}</span>
  <span class="n">out_aval</span> <span class="o">=</span> <span class="n">pos_aval</span><span class="o">.</span><span class="n">update</span><span class="p">(</span><span class="n">named_shape</span><span class="o">=</span><span class="n">named_shape</span><span class="p">)</span>
  <span class="n">effects</span> <span class="o">=</span> <span class="p">{</span><span class="o">*</span><span class="nb">map</span><span class="p">(</span><span class="n">core</span><span class="o">.</span><span class="n">NamedAxisEffect</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)}</span>
  <span class="k">return</span> <span class="n">out_aval</span><span class="p">,</span> <span class="n">effects</span>


<span class="k">def</span> <span class="nf">_pdot_vmap_collective_rule</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span>
                               <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="n">x_dim</span><span class="p">,</span> <span class="n">y_dim</span> <span class="o">=</span> <span class="n">dims_in</span>
  <span class="n">x_pos_contract</span><span class="p">,</span> <span class="n">y_pos_contract</span> <span class="o">=</span> <span class="n">pos_contract</span>
  <span class="n">x_pos_contract</span> <span class="o">=</span> <span class="p">[</span><span class="n">x_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&gt;=</span> <span class="n">x_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">x_pos_contract</span><span class="p">]</span>
  <span class="n">y_pos_contract</span> <span class="o">=</span> <span class="p">[</span><span class="n">y_dim</span><span class="p">]</span> <span class="o">+</span> <span class="p">[</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&gt;=</span> <span class="n">y_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">y_pos_contract</span><span class="p">]</span>
  <span class="n">x_pos_batch</span><span class="p">,</span> <span class="n">y_pos_batch</span> <span class="o">=</span> <span class="n">pos_batch</span>
  <span class="n">x_pos_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&gt;=</span> <span class="n">x_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">x_pos_batch</span><span class="p">]</span>
  <span class="n">y_pos_batch</span> <span class="o">=</span> <span class="p">[</span><span class="n">d</span> <span class="o">+</span> <span class="p">(</span><span class="n">d</span> <span class="o">&gt;=</span> <span class="n">y_dim</span><span class="p">)</span> <span class="k">for</span> <span class="n">d</span> <span class="ow">in</span> <span class="n">y_pos_batch</span><span class="p">]</span>
  <span class="n">remaining_axis_names</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">n</span> <span class="k">for</span> <span class="n">n</span> <span class="ow">in</span> <span class="n">axis_name</span> <span class="k">if</span> <span class="n">n</span> <span class="o">!=</span> <span class="n">frame_name</span><span class="p">)</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">pdot_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">remaining_axis_names</span><span class="p">,</span>
                    <span class="n">pos_contract</span><span class="o">=</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">x_pos_contract</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_pos_contract</span><span class="p">)),</span>
                    <span class="n">pos_batch</span><span class="o">=</span><span class="p">(</span><span class="nb">tuple</span><span class="p">(</span><span class="n">x_pos_batch</span><span class="p">),</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">y_pos_batch</span><span class="p">)),</span>
                    <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="kc">None</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">pdot_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_pdot_vmap_collective_rule</span>

<span class="k">def</span> <span class="nf">_pdot_vmap_batching_rule</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span>
                             <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="p">(</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">),</span> <span class="n">result_batch_dim</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">_dot_general_batch_dim_nums</span><span class="p">(</span>
      <span class="p">(</span><span class="n">x</span><span class="o">.</span><span class="n">ndim</span><span class="p">,</span> <span class="n">y</span><span class="o">.</span><span class="n">ndim</span><span class="p">),</span> <span class="n">dims_in</span><span class="p">,</span> <span class="p">[</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">])</span>
  <span class="n">out</span> <span class="o">=</span> <span class="n">pdot_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">axis_name</span><span class="o">=</span><span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="o">=</span><span class="n">pos_contract</span><span class="p">,</span>
                    <span class="n">pos_batch</span><span class="o">=</span><span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">out</span><span class="p">,</span> <span class="n">result_batch_dim</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">pdot_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_pdot_vmap_batching_rule</span>


<span class="k">def</span> <span class="nf">_pdot_lowering</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="n">local_out</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">dot_general</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="o">=</span><span class="p">(</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">),</span>
                              <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span> <span class="n">preferred_element_type</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">psum</span><span class="p">(</span><span class="n">local_out</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">)</span> <span class="k">if</span> <span class="n">axis_name</span> <span class="ow">is</span> <span class="ow">not</span> <span class="kc">None</span> <span class="k">else</span> <span class="n">local_out</span>

<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span>
    <span class="n">pdot_p</span><span class="p">,</span>
    <span class="n">mlir</span><span class="o">.</span><span class="n">lower_fun</span><span class="p">(</span><span class="n">_pdot_lowering</span><span class="p">,</span> <span class="n">multiple_results</span><span class="o">=</span><span class="kc">False</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_pdot_transpose_lhs</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="c1"># TODO: avals with names, call pbroadcast with axis_name</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">_dot_general_transpose_lhs</span><span class="p">(</span>
      <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="o">=</span><span class="p">[</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">],</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
      <span class="n">preferred_element_type</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="k">def</span> <span class="nf">_pdot_transpose_rhs</span><span class="p">(</span><span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axis_name</span><span class="p">,</span> <span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">,</span> <span class="n">precision</span><span class="p">):</span>
  <span class="c1"># TODO: avals with names, call pbroadcast with axis_name</span>
  <span class="k">return</span> <span class="n">lax</span><span class="o">.</span><span class="n">_dot_general_transpose_rhs</span><span class="p">(</span>
      <span class="n">g</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="o">=</span><span class="p">[</span><span class="n">pos_contract</span><span class="p">,</span> <span class="n">pos_batch</span><span class="p">],</span> <span class="n">precision</span><span class="o">=</span><span class="n">precision</span><span class="p">,</span>
      <span class="n">preferred_element_type</span><span class="o">=</span><span class="kc">None</span><span class="p">)</span>
<span class="n">ad</span><span class="o">.</span><span class="n">defbilinear</span><span class="p">(</span><span class="n">pdot_p</span><span class="p">,</span> <span class="n">_pdot_transpose_lhs</span><span class="p">,</span> <span class="n">_pdot_transpose_rhs</span><span class="p">)</span>


<span class="k">def</span> <span class="nf">_pgather_impl</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
  <span class="k">assert</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)</span>
  <span class="n">src_axes_front</span> <span class="o">=</span> <span class="n">moveaxis</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">axes</span><span class="p">,</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">)))</span>
  <span class="n">non_axes_shape</span> <span class="o">=</span> <span class="n">src_axes_front</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="nb">len</span><span class="p">(</span><span class="n">axes</span><span class="p">):]</span>
  <span class="n">src_one_axis_front</span> <span class="o">=</span> <span class="n">src_axes_front</span><span class="o">.</span><span class="n">reshape</span><span class="p">((</span><span class="o">-</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">non_axes_shape</span><span class="p">)</span>
  <span class="n">slice_sizes</span> <span class="o">=</span> <span class="p">(</span><span class="mi">1</span><span class="p">,)</span> <span class="o">+</span> <span class="n">non_axes_shape</span>
  <span class="n">idx</span> <span class="o">=</span> <span class="n">lax</span><span class="o">.</span><span class="n">expand_dims</span><span class="p">(</span><span class="n">idx</span><span class="p">,</span> <span class="p">(</span><span class="o">-</span><span class="mi">1</span><span class="p">,))</span>
  <span class="n">offset_dims</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">idx</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span><span class="p">,</span> <span class="n">idx</span><span class="o">.</span><span class="n">ndim</span> <span class="o">+</span> <span class="n">src_one_axis_front</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">2</span><span class="p">))</span>
  <span class="n">dnums</span> <span class="o">=</span> <span class="n">slicing</span><span class="o">.</span><span class="n">GatherDimensionNumbers</span><span class="p">(</span>
      <span class="n">offset_dims</span><span class="o">=</span><span class="n">offset_dims</span><span class="p">,</span>
      <span class="n">collapsed_slice_dims</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,),</span>
      <span class="n">start_index_map</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,))</span>
  <span class="k">return</span> <span class="n">slicing</span><span class="o">.</span><span class="n">gather</span><span class="p">(</span><span class="n">src_one_axis_front</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">dimension_numbers</span><span class="o">=</span><span class="n">dnums</span><span class="p">,</span>
                        <span class="n">slice_sizes</span><span class="o">=</span><span class="nb">tuple</span><span class="p">(</span><span class="n">slice_sizes</span><span class="p">))</span>

<span class="k">def</span> <span class="nf">_pgather_abstract_eval</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
  <span class="c1"># TODO: Avals with names rule: remove all axes from src, insert those from idx</span>
  <span class="c1">#       The order is important, because it is ok to re-insert one of the deleted axes!</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">src</span><span class="o">.</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">((</span><span class="n">a</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="n">axes</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="nb">int</span><span class="p">)),</span> <span class="n">reverse</span><span class="o">=</span><span class="kc">True</span><span class="p">):</span>
    <span class="k">del</span> <span class="n">shape</span><span class="p">[</span><span class="n">axis</span><span class="p">]</span>
  <span class="n">shape</span> <span class="o">=</span> <span class="n">idx</span><span class="o">.</span><span class="n">shape</span> <span class="o">+</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">shape</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">ShapedArray</span><span class="p">(</span><span class="n">shape</span><span class="p">,</span> <span class="n">src</span><span class="o">.</span><span class="n">dtype</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_pgather_parallel_lowering</span><span class="p">(</span><span class="n">ctx</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
  <span class="k">if</span> <span class="nb">any</span><span class="p">(</span><span class="ow">not</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">):</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;pgather only supported in the SPMD lowering.&quot;</span>
                              <span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="k">return</span> <span class="n">mlir</span><span class="o">.</span><span class="n">lower_fun</span><span class="p">(</span><span class="n">_pgather_impl</span><span class="p">,</span> <span class="n">multiple_results</span><span class="o">=</span><span class="kc">False</span><span class="p">)(</span>
      <span class="n">ctx</span><span class="p">,</span> <span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">_pgather_batcher</span><span class="p">(</span><span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
  <span class="n">src</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="n">dsrc</span><span class="p">,</span> <span class="n">didx</span> <span class="o">=</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">didx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span> <span class="ow">and</span> <span class="n">dsrc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="c1"># NB: We could just go forward with it and take the diagonal along the</span>
    <span class="c1">#     two axes we get in the output, but that would be quite inefficient</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="k">elif</span> <span class="n">didx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">pgather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">),</span> <span class="n">didx</span>
  <span class="k">elif</span> <span class="n">dsrc</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="n">src_last_batched</span> <span class="o">=</span> <span class="n">moveaxis</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">dsrc</span><span class="p">,</span> <span class="o">-</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">result</span> <span class="o">=</span> <span class="n">pgather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">src_last_batched</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">axes</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">result</span><span class="p">,</span> <span class="n">result</span><span class="o">.</span><span class="n">ndim</span> <span class="o">-</span> <span class="mi">1</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">assert</span> <span class="kc">False</span>  <span class="c1"># This shouldn&#39;t get called anyway</span>

<span class="k">def</span> <span class="nf">_pgather_collective_batcher</span><span class="p">(</span><span class="n">axis_size</span><span class="p">,</span> <span class="n">frame_name</span><span class="p">,</span> <span class="n">_</span><span class="p">,</span> <span class="n">vals_in</span><span class="p">,</span> <span class="n">dims_in</span><span class="p">,</span> <span class="o">*</span><span class="p">,</span> <span class="n">axes</span><span class="p">):</span>
  <span class="n">src</span><span class="p">,</span> <span class="n">idx</span> <span class="o">=</span> <span class="n">vals_in</span>
  <span class="n">dsrc</span><span class="p">,</span> <span class="n">didx</span> <span class="o">=</span> <span class="n">dims_in</span>
  <span class="k">if</span> <span class="n">dsrc</span> <span class="ow">is</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="k">raise</span> <span class="ne">ValueError</span><span class="p">(</span><span class="s2">&quot;pgather axis </span><span class="si">{frame.name}</span><span class="s2"> is missing from the indexed value&quot;</span><span class="p">)</span>
  <span class="k">if</span> <span class="n">didx</span> <span class="ow">is</span> <span class="ow">not</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span><span class="p">:</span>
    <span class="c1"># NOTE: This is allowed and the output would be mapped along this axis!</span>
    <span class="k">raise</span> <span class="ne">NotImplementedError</span><span class="p">(</span><span class="s2">&quot;Please open a feature request!&quot;</span><span class="p">)</span>
  <span class="c1"># Now source is mapped, idx is not</span>
  <span class="n">new_axes</span> <span class="o">=</span> <span class="nb">tuple</span><span class="p">(</span><span class="n">dsrc</span> <span class="k">if</span> <span class="n">axis</span> <span class="o">==</span> <span class="n">frame_name</span> <span class="k">else</span>
                   <span class="n">axis</span> <span class="o">+</span> <span class="p">(</span><span class="n">dsrc</span> <span class="o">&lt;=</span> <span class="n">axis</span><span class="p">)</span> <span class="k">if</span> <span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">else</span>
                   <span class="n">axis</span>
                   <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">)</span>
  <span class="c1"># The result is not mapped, because we eliminate all axes, and those include</span>
  <span class="c1"># the batched axis.</span>
  <span class="k">if</span> <span class="nb">all</span><span class="p">(</span><span class="nb">isinstance</span><span class="p">(</span><span class="n">axis</span><span class="p">,</span> <span class="nb">int</span><span class="p">)</span> <span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="n">axes</span><span class="p">):</span>
    <span class="c1"># We rewrite a purely positional pgather as a gather, because that one</span>
    <span class="c1"># is more fully featured (e.g. supports AD).</span>
    <span class="k">return</span> <span class="n">_pgather_impl</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">new_axes</span><span class="p">),</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span>
  <span class="k">else</span><span class="p">:</span>
    <span class="k">return</span> <span class="n">pgather_p</span><span class="o">.</span><span class="n">bind</span><span class="p">(</span><span class="n">src</span><span class="p">,</span> <span class="n">idx</span><span class="p">,</span> <span class="n">axes</span><span class="o">=</span><span class="n">new_axes</span><span class="p">),</span> <span class="n">batching</span><span class="o">.</span><span class="n">not_mapped</span>

<span class="n">pgather_p</span> <span class="o">=</span> <span class="n">core</span><span class="o">.</span><span class="n">AxisPrimitive</span><span class="p">(</span><span class="s1">&#39;pgather&#39;</span><span class="p">)</span>
<span class="n">pgather_p</span><span class="o">.</span><span class="n">def_impl</span><span class="p">(</span><span class="n">_pgather_impl</span><span class="p">)</span>
<span class="n">pgather_p</span><span class="o">.</span><span class="n">def_abstract_eval</span><span class="p">(</span><span class="n">_pgather_abstract_eval</span><span class="p">)</span>
<span class="n">mlir</span><span class="o">.</span><span class="n">register_lowering</span><span class="p">(</span><span class="n">pgather_p</span><span class="p">,</span> <span class="n">_pgather_parallel_lowering</span><span class="p">)</span>
<span class="c1"># TODO: Transpose? That requires adding pscatter...</span>
<span class="n">batching</span><span class="o">.</span><span class="n">primitive_batchers</span><span class="p">[</span><span class="n">pgather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_pgather_batcher</span>
<span class="n">batching</span><span class="o">.</span><span class="n">axis_primitive_batchers</span><span class="p">[</span><span class="n">pgather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">_pgather_collective_batcher</span>
<span class="n">core</span><span class="o">.</span><span class="n">axis_substitution_rules</span><span class="p">[</span><span class="n">pgather_p</span><span class="p">]</span> <span class="o">=</span> <span class="n">partial</span><span class="p">(</span><span class="n">_subst_all_names_in_param</span><span class="p">,</span> <span class="s1">&#39;axes&#39;</span><span class="p">)</span>
</pre></div>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By The JAX authors
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      Â© Copyright 2024, The JAX Authors. NumPy and SciPy documentation are copyright the respective authors..
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="../../../../_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="../../../../_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>